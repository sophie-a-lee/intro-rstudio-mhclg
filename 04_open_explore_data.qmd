---
code-annotations: hover
---

# Opening and exploring data

## Styles of R coding
Up to this point, beyond the style tips sprinkled through these notes, we have not thought about the style of R coding we will be using. There are different approaches to R coding that we can use, they can be thought of as different dialects of the R programming language. 

The choice of R 'dialect' depends on personal preference. Some prefer to use the 'base R' approach that does not rely on any packages that may need updating, making it a more stable approach. However, base R can be difficult to read for those not comfortable with coding. 

```{r}
#| label: boyfriend meme 
#| echo: false
#| warning: false
#| message: false
#| 

library(tidyverse)
memer::meme_get("DistractedBf") %>% 
  memer::meme_text_distbf("tidyverse", "new R users", "base R")
```


The alternative approach that we will be adopting in this course is the '`tidyverse`' approach. Tidyverse is a set of packages that have been designed to make R coding more readable and efficient. They have been designed with reproducibility in mind, which means there is a wealth of online (mostly free), well-written resources available to help use these packages. Tidyverse is also the preferred coding style of the Government Analysis Function guidance.

If you have not done so already, install the `tidyverse` packages to your machine using the following code:

```{r install tidyverse, eval = FALSE}
install.packages('tidyverse')
```

:::{.callout-warning}
This can take a long time if you have never downloaded the tidyverse packages before as there are many dependencies that are required. 

Do not stress if you get a lot of text in the console! This is normal, but watch out for any error messages.
:::

Once the `tidyverse` package is installed, we must load it into the current working session. At the beginning of your script file add the following syntax:

```{r load tidyverse}
pacman::p_load(tidyverse)
```

:::{.stylebox}

::::{.stylebox-header}
:::::{.stylebox-icon}
:::::
Style tip
::::

::::{.stylebox-body}
The double colon in R can be used to run a function within an installed package without loading the entire package to an R session.
::::

:::

## The working directory
The working directory is a file path on your computer that R sets as the default location when opening, saving, or exporting documents, files, and graphics. This file path can be specified manually but setting the working directory saves time and makes code more efficient. 

The working directory can be set manually by using the *Session -> Set Working Directory -> Change Directory…* option from the drop-down menu, or the `setwd` function. Both options require the directory to be specified each time R is restarted, are sensitive to changes in folders within the file path, and cannot be used when script files are shared between colleagues.

An alternative approach that overcomes all these issues is to create an R project.

### R projects
R projects are files (saved with the `.Rproj` extension) that keep associated files (including scripts, data, and outputs) grouped together. An R project automatically sets the working directory relative to its current location, which makes collaborative work easier, and avoids issues when a file path is changed.

Projects are created by using the *File -> New project* option from the drop-down menu, or using the ![R project icon](img/project_icon.png) icon from the top-right corner of the RStudio interface. Existing projects can be opened under the *File -> Open project...* drop-down menu or using the project icon. 

When creating a new project, we must choose whether we are creating a new directory or using an existing one. Usually, we will have already set up a folder containing data or other documents related to the analysis we plan to carry out. If this is the case, we are using an existing directory and selecting the analysis folder as the project directory.

:::{.stylebox}

::::{.stylebox-header}
:::::{.stylebox-icon}
:::::
Style tip
::::

::::{.stylebox-body}
Have a clear order to your analysis folder. Consider creating separate folders within a project for input and output data, documentation, and outputs such as graphs or tables.
::::

:::

## Loading data
To ensure our code is collaborative and reproducible, we should strive to store data in formats that can be used across multiple platforms. One of the best ways to do this is to store data as a comma-separated file (.csv). CSV files can be opened by a range of different softwares (including R, SPSS, STATA and excel), and base R can be used to open these files without requiring additional packages. 

Unfortunately, we are not always able to choose the format that data are stored in. For example, the English Housing Survey (EHS) data is stored as a .sav (SPSS) data file. Fortunately for us, R has a wide range of packages that have been developed to load data from every conceivable format. 

The package that we will be using the load SPSS data is the `haven` package. To ensure this is loaded in at the beginning of each session, adapt the previous `p_load` function:

```{r load haven package, warning = FALSE, message = FALSE}
pacman::p_load(tidyverse, haven)
```

To avoid any errors arising from spelling mistakes, we can use the `list.files` function, which returns a list of files and folders from the current working directory. The file names can be copied from the console and pasted into the script file. As the data are saved in a folder within the working directory, we add the argument `path = ` to specify the folder we want to list files from.

```{r list files}
list.files(path = "data")
```

The first data set we will load is the`generalfs21_EUL.sav` file. This contains general information taken from the English Housing Survey (EHS) from 2021, including a unique identifier, the respondents' region, and the tenure type. 

The EHS data can be loaded into R using the `read_spss` function, and saved as an object using the `<-` symbol:

```{r load ehs general}
ehs_general <- read_spss(file = "data/generalfs21_EUL.sav")
```

The imported data will appear in the environment with its given name. The contents of the object can be viewed by clicking on the object name in the environment, opening a tab next to script files. This window is a preview so cannot be edited here.

Some useful functions that can be used to explore a dataset include:

```{r names function}
names(ehs_general) #<1>

head(ehs_general) #<2>

tail(ehs_general) #<3>

str(ehs_general) #<4>
```

1. Return variable names
2. Returns the first 6 rows
3. Returns the last 6 rows
4. Gives information about the structure of an object (including variable types)

The `str` function tells us that this object is a `tibble`. This is tidyverse language for a data set (in base R, it is known as a `data.frame`). All variables are recognised as `dbl + lbl`, or labelled double variables. Double is tidyverse language for numeric data, and labels are taken from the original SPSS data. 

It is important to check that R has correctly recognised variable type when data are loaded, before generating any visualisations or analysis. If variables are incorrectly specified, this could either lead to errors or invalid analyses. We will see how to change variables types later in this chapter.

The variables in this tibble contain additional information, stored as `attributes`. Data imported from other sources do not typically include these attributes by default, but these are able to uphold any information that was stored in the 'Variable view' window of SPSS.

:::{.callout-tip}
## Hint

To remove any of the attributes imported from an SPSS file, we can use `haven` packages `zap` functions. For example, `zap_widths(x)` would remove the width attributes from an object `x`, and `zap_labels(x)` would remove value labels. For more information, see [this article](https://haven.tidyverse.org/articles/semantics.html). 
:::

## Selecting variables
Often, we will not need every variable in a downloaded dataset to carry out an analysis, and we may wish to create a smaller analysis tibble. We may also wish to select individual variables from the tibble to apply functions to them without including the entire dataset. 

To select one or more variable and return them as a new tibble, we can use the `select` function from tidyverse's `dplyr` package.

For example, we do not need all the variables contained in the EHS general dataset. The variables we are interested in keeping are the unique identifier variables (`serialanon`), the survey weights (`aagfh21`), the tenure type response with 4 options (`tenure4x`), and the Government office region (`govreg1`):

```{r select ehs general}
select(ehs_general, serialanon, aagfh21, tenure4x, gorehs) #<1>

select(ehs_general, 1, 2, 5, 7) #<2>
```

1. Variables can be selected using their names
2. Or their column number

The `select` function can also be combined with a number of 'selection helper' functions that help us select variables based on naming conventions:

- `starts_with("xyz")` returns all variables with names beginning `xyz`
- `ends_with("xyz")` returns all variables with names ending `xyz`
- `contains("xyz")` returns all variables that have `xyz` within their name

Or based on whether they match a condition:

- `where(is.numeric)` returns all variables that are classed as numeric

For a full list of these selection helpers, access the helpfile using `?tidyr_tidy_select`.

The `select` function can also be used to remove variables from a tibble by adding a `-` before the variable name or number. For example, to return the EHS general dataset without the unique identifier variable, we use:

```{r ehs general remove id}
select(ehs_general, -serialanon)
```

After making changes to the analysis dataset, it is useful to save this data separately to the original raw data. This can be done using the `write_csv` function. 

```{r save ehs updated data}
ehs_general_reduced <- select(ehs_general, serialanon, aagfh21, 
                              tenure4x, gorehs)
```

```{r write_csv, eval = FALSE}
write_csv(ehs_general_reduced, 
          file = "saved_data/ehs_general_reduced.csv")
```

:::{.callout-warning}
When saving updated tibbles as files, use a different file name to the original raw data. Using the same name will overwrite the original file. We always want a copy of the original in case of any errors or issues.
:::

The `select` function returns variables as a tibble object. However, some functions, for example summary functions from base R, require data in the form of a `vector`. Vectors are lists of values with no formal structure, unlike a tibble which is structured to have rows and columns. To return a single variable as a vector, we can use the `$` symbol between the data name and the variable to return:

```{r ehs_general vector, eval = FALSE}
ehs_general_reduced$aagfh21
```

## Filtering data {#sec-filter}
The `filter` function, from tidyverse's `dplyr` package allows us to return subgroups of the data based on conditional statements. These conditional statements can include mathematical operators:

- `<=` less than or equal to, 
- `<` less than,
- `>=` greater than or equal to,
- `>` greater than,
- `==` is equal to, 
- `!=` is not equal to, 

or can be based on conditional functions:

- `is.na(variable)` where variable is missing, 
- `between(variable, a, b)` where variable lies between a and b.

A list of these conditional statements can be found in the help file using `?filter`.

For example, we may wish to return rows from the EHS dataset that were privately rented. To check which number refers to privately rented, we can check the `labels` attribute of the `tenure4x` variable which shows the labels from the SPSS file:

```{r labels attribute}
attributes(ehs_general_reduced$tenure4x)$labels
```

Private rented is given by a 2 in the current dataset, therefore our conditional statement will return rows where the `tenure4x` variable takes the value 2.

```{r filter tenure private rented}
filter(ehs_general_reduced, tenure4x == 2)
```

Multiple conditional statements can be added to the same function by separating them with a comma `,` where we want all conditions met, or the `|` in place of or. To return all respondents that lived in privately rented accommodation in the North East, we can extend the previous filter statement:

```{r filter privately rented in NE}
attributes(ehs_general_reduced$gorehs)$labels

# North East is region 1
filter(ehs_general_reduced, tenure4x == 2, gorehs == 1)
```

## Pipes
When creating an analysis-ready dataset, we often want to combine functions such as `select` and `filter`. Previously, these would need to be carried out separately and a new object would need to be created or overwritten at each step, clogging up the environment. 

In `tidyverse`, we combine functions within a single process using the **pipe** symbol `%>%`, which is read as **and then** within the code. For example, if we wanted to just select the unique identifiers of respondents that were privately renting in the North East, we could do this in a single process:

```{r piped ID for private rent in NE}
ehs_general_reduced %>% 
  filter(tenure4x == 2, gorehs == 1) %>% 
  select(serialanon)
```

:::{.stylebox}

::::{.stylebox-header}
:::::{.stylebox-icon}
:::::
Style tip
::::

::::{.stylebox-body}
When combining multiple functions within a process using pipes, it is good practice to start the code with the data and pipe that into the functions, rather than including it in the function itself.
::::

:::

:::{.callout-tip}
### Hint

Rather than typing out pipes every time, use the keyboard shortcut *ctrl + shift + m* for Windows and *Command + shift + m* for Mac.
:::

## Creating new variables
The function `mutate` from tidyverse's `dplyr` package allows us to add new variables to a dataset. We can add multiple variables within the same function, separating each with a comma `,`. 

The `mutate` function is helpful when variable types are not correctly specified by R when they are read in. For example, the region and tenancy type variables in the `ehs_general_reduced` tibble are categorical variables but are currently recognised as numeric. 

Categorical variables in R are known as **factors**. These factors can be ordered and can have labels assigned to different levels. To convert an existing variable to a factor, we can use the `factor` or `as_factor` functions. Here, we can combine the `mutate` and `as_factor` functions to convert tenancy type and region to factors:

```{r mutate region and tenancy}
ehs_general_reduced <- mutate(ehs_general_reduced,
                              tenancy_type = as_factor(tenure4x),
                              region = as_factor(gorehs))
```

:::{.callout-note}
As this data was taken from an SPSS file that had labels attached to the grouped variables, we do not need to specify these within the `as_factor` function. 

When the variables do not have this labelling structure already, they will need to be added using the `label` argument of the `factor` function (see `?factor` for more information).
:::

The `mutate` function can also be used to convert numeric variables into an ordered categorical variable, and can be used to transform variables using mathematical functions. For example, we can create two new variables, first giving the square root of the weighting variable, and second grouping the weighting variable into three categories (low: $< 1000$, medium: $1000 \leq$ `aagfh21` $< 5000$, high: $\geq 5000$):

```{r mutate weights}
ehs_general_reduced <- mutate(ehs_general_reduced,
                              weighting_sqrt = sqrt(aagfh21),
                              weighting_fct = cut(aagfh21, 
                                                  breaks = c(0, 1000, 
                                                             5000, Inf),
                                                  right = TRUE,
                                                  labels = c("Low", "Medium",
                                                              "High")))
```

:::{.callout-warning}
The example converting our weighting variable into a categorical alternative is **purely for deomstrative purposes**. In reality, we would not treat a weighting variable this way. 
:::
  
:::{.callout-tip}
## Hint

The `c` function takes a list of values separated by commas and returns them as a `vector`. This is useful when a function argument requires multiple values and we don't want R to move onto the next argument (which is what a comma inside functions usually means).
:::

## Other useful `dplyr` functions
To ensure our code follows the [tidyverse style guide](https://style.tidyverse.org/), variable names should be concise, *informative*, and contain no special charaters (other than `_`). The original variable names given in the original EHS data were definitely not stylish! To change names in a dataset, we can use the `rename` function:

```{r rename ehs_general}
ehs_general_reduced <- rename(ehs_general_reduced,
                              id = serialanon,
                              weighting = aagfh21)
```

For more useful data exploration and manipulation functions from the `dplyr` package, I would recommending taking a look at the **vignette** associated with the package (a long-form version of a help file):

`vignette("dplyr")`

Or look at the `dplyr` [web page and cheatsheet](https://dplyr.tidyverse.org/index.html). 


## A smooth process to the analysis dataset
Our EHS analysis dataset has been created haphazardly through this chapter to demonstrate each step separately. In reality, we would load this data and manipulate it in one process, separating steps by pipes `%>%`. 

The code below takes the data from its saw form (the .sav file) and transforms it into a clean dataset that we will be using for the rest of the course:

```{r ehs_general tidy, results = "hide"}
ehs_general_tidy <- read_spss(file = "Data/generalfs21_EUL.sav") %>% #<1>
                    mutate(tenure_type = as_factor(tenure4x), #<2>
                           region = as_factor(gorehs)) %>% #<2>
                    rename(id = serialanon, #<3>
                           weighting = aagfh21) %>% #<3>
                    select(id, weighting, tenure_type, region) #<4>

str(ehs_general_tidy) #<5>

write_csv(ehs_general_tidy, file = "saved_data/ehs_general_tidy.csv") #<6>
```

1. Step 1: load the dataset into R and attach as an object
2. Step 2: convert grouping variables into factors
3. Step 3: rename other variables to avoid confusion
4. Step 4: keep only the necessary variables
5. Check the new data looks correct
6. Step 5: save this tidy data as a new file in a saved_data folder

## Exercise 3 {.unnumbered}
1. You have been provided with another .sav file which contains the interview responses from the EHS. Create and save a tidy version of this dataset, ensuring variables are classified as the correct type and names follow the style conventions (if you cannot remember these, check [here](https://style.tidyverse.org/syntax.html) for a reminder).

The variables we need in the tidy dataset are:

- The unique identifier `serialanon`
- The gross household income `HYEARGRx`
- The length of residence `lenresb`
- The weekly rent `rentwkx` and mortgage `mortwkx` payments
- Whether the property is freehold or leasehold `freeLeas`

:::{.callout-caution collapse="true"}
## Exercise hint

The functions required for this exercise are `read_spss`, `str`, `mutate`, `as_factor`, `rename`.
:::

2. Save the tidy interview dataset as a csv file with an appropriate file name.

3. Using the new, tidy dataset, answer the following questions:

- How many respondents paid weekly rent of between £150 and £300?
- How many respondents did not give a response to either the weekly rent or weekly mortgage question?
- What is the highest household gross income of these responders? 

:::{.callout-caution collapse="true"}
## Exercise hint

This exercise requires you to create a subgroup which just contains observations that match the condition given (see @sec-filter), and `count` the number of rows in the subgroup. 

For the final part, use the `max` function to return the maximum recorded value. Check that this value actually represents an income.
:::