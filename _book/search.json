[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Introduction to quantitative analysis with R",
    "section": "",
    "text": "Welcome!\nWelcome to the Introduction to Quantitative Analysis with R course, designed for and with the Department for Levelling Up, Housing and Communities (DLUCH). This course aims to introduce R and RStudio software. R is an open-source software that was designed to make data analysis more accessible, reproducible, and user friendly.\nThis two-day course will equip you with the essential skills to leverage the power of R for your data analysis. We will begin with a gentle introduction to the RStudio interface and the basics of the R coding language (or syntax). We will then see how R can be used to efficiently load, clean and transform data. Finally, we will use R to produce clear, compelling visualisations and tables to communicate findings.\nThroughout the course, we will discuss best practices for reproducible data analysis, ensuring that all code adheres to the Analysis Standards as recommended by the Aqua book.",
    "crumbs": [
      "Welcome!"
    ]
  },
  {
    "objectID": "index.html#data-for-the-course",
    "href": "index.html#data-for-the-course",
    "title": "Introduction to quantitative analysis with R",
    "section": "Data for the course",
    "text": "Data for the course\nThis course uses data from the English Housing Survey (EHS) from 2021 and the Office for Budget Responsibility (OBR) 2024 economic and fiscal outlook. All data used in the course can be downloaded from the course repository.\nBefore beginning the course, please save these files into a folder called ‘data’ within the folder you will be working from during the course.",
    "crumbs": [
      "Welcome!"
    ]
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Introduction to RStudio",
    "section": "",
    "text": "1.1 The RStudio console window\nThe screenshot below shows the RStudio interface which comprises of four windows:",
    "crumbs": [
      "Introduction to R and RStudio",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to RStudio</span>"
    ]
  },
  {
    "objectID": "intro.html#the-rstudio-console-window",
    "href": "intro.html#the-rstudio-console-window",
    "title": "1  Introduction to RStudio",
    "section": "",
    "text": "RStudio console window\n\n\n\n1.1.1 Window A: R script files\nAll analysis and actions in R are carried out using the R syntax language. R script files allow us to write and edit code before running it in the console window.\n\n\n\n\n\n\nStyle tip\n\n\n\nLimit script files to 80 characters per line to ensure it is readable.\nRStudio has an option to add a margin that makes this easier to adhere to. Under the Tools drop-down menu, select Global options. Select Code from the list on the right, then under the Display tab, tick the Show margin box.\n\n\nIf this window is not visible, create a new script file using File -&gt; New File -&gt; R Script option from the drop-down menus or clicking the  icon above the console and selecting ‘R Script’. This will open a new, blank script file. More than one script file can be open at the same time.\nCode entered into the script file does not run automatically. To run commands, highlight the code from the script file and click the  icon above the top right corner of the script window (this can be carried out by pressing Ctrl + Enter in Windows or Command + Enter on a Mac computer). Multiple lines of code can be run at once.\nThe main advantage of using the script file rather than entering the code directly into the console is that it can be saved, edited and shared. To save a script file, use File -&gt; Save As… from the drop down menu, click the  icon at the top of the window, or use the keyboard shortcut ctrl + s for Windows and command + s for Mac. It is important to save the script files at regular intervals to avoid losing work.\n\n\n\n\n\n\nStyle tip\n\n\n\nScript file names should be meaningful, lower case, and end in .R. Avoid using special characters in file names, including spaces. Use _ instead of spaces.\nWhere files should be run in a specific order, prefix the file name with numbers.\n\n\nPast script files can be opened using File -&gt; Open File… from the drop-down menu, by clicking the  icon, or using the keyboard shortcut ctrl + o for Windows and command + o for Mac, then selecting a *.R file.\n\n\n1.1.2 Window B: R console\nThe R console window is where all commands run from the script file, results (other than plots), and messages, such as errors, are displayed. Commands can be written directly into the R console after the &gt; symbol and executed using Enter on the keyboard. It is not recommended to write code directly into the console as it is cannot be saved or replicated.\nEvery time a new R session is opened, details about version and citations of R will be given by default. To clear text from the console window, use the keyboard shortcut control + l (this is the same for both Windows and Mac users). Be aware that this clears all text from the console, including any results. Before running this command, check that any results can be replicated within the script file.\n\n\n1.1.3 Window C: Environment and history\nThis window lists all data and objects currently loaded into R, and is not available in the basic R software. More details on the types of objects and how to use the Environment window are given in later sections.\n\n\n1.1.4 Window D: Files, plots, packages and help\nThis window has many potential uses: plots are displayed and can be saved from here, and R help files will appear here. This window is only available in the RStudio interface and not in the basic R package.",
    "crumbs": [
      "Introduction to R and RStudio",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to RStudio</span>"
    ]
  },
  {
    "objectID": "intro.html#exercise-1",
    "href": "intro.html#exercise-1",
    "title": "1  Introduction to RStudio",
    "section": "Exercise 1",
    "text": "Exercise 1\n\nOpen a new script file if you have not already done so.\nSave this script file into an appropriate location.",
    "crumbs": [
      "Introduction to R and RStudio",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction to RStudio</span>"
    ]
  },
  {
    "objectID": "syntax.html",
    "href": "syntax.html",
    "title": "2  R syntax",
    "section": "",
    "text": "2.1 Exercise 2\nFor each part of question 2, copy the result from the console and paste them onto the same line of the script file as the code. Do this in a way that ensures there are no error messages if you were to run the entire script file.",
    "crumbs": [
      "Introduction to R and RStudio",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>R syntax</span>"
    ]
  },
  {
    "objectID": "syntax.html#exercise-2",
    "href": "syntax.html#exercise-2",
    "title": "2  R syntax",
    "section": "",
    "text": "Add your name and the date to the top of your script file (hint: comment this out so R does not try to run it)\nUse R to answer to following sums:\n\n\n\\(64^2\\)\n\\(3432 \\div 8\\)\n\\(96 \\times 72\\)",
    "crumbs": [
      "Introduction to R and RStudio",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>R syntax</span>"
    ]
  },
  {
    "objectID": "objects_functions.html",
    "href": "objects_functions.html",
    "title": "3  R objects, functions and packages",
    "section": "",
    "text": "3.1 Objects\nOne of the main advantages to using R over other software packages such as SPSS is that more than one dataset can be accessed at the same time. A collection of data stored in any format within the R session is known as an object. Objects can include single numbers, single variables, entire datasets, lists of datasets, or even tables and graphs.\nObjects are defined in R using the &lt;- symbol or =. For example,\nobject_1 &lt;- 81\nCreates an object in the environment named object_1, which takes the value 81. This will appear in the environment window of the console (window C from the interface shown in the introduction).\nTo retrieve an object, type its name into the script or console and run it. This object can then be included in functions or operations in place of the value assigned to it:\nobject_1\n\n[1] 81\n\nsqrt(object_1)\n\n[1] 9\nR has some mathematical objects stored by default such as pi that can be used in calculations.\npi\n\n[1] 3.141593",
    "crumbs": [
      "Introduction to R and RStudio",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>R objects, functions and packages</span>"
    ]
  },
  {
    "objectID": "objects_functions.html#objects",
    "href": "objects_functions.html#objects",
    "title": "3  R objects, functions and packages",
    "section": "",
    "text": "Style tip\n\n\n\nObject names should only contain lower case letters, numbers and _ (instead of a space to separate words). They should be meaningful and concise.\n\n\n\n\n\n\n\n\n\n\n\nStyle tip\n\n\n\nAlthough both work, use &lt;- for assignment, not =.",
    "crumbs": [
      "Introduction to R and RStudio",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>R objects, functions and packages</span>"
    ]
  },
  {
    "objectID": "objects_functions.html#functions",
    "href": "objects_functions.html#functions",
    "title": "3  R objects, functions and packages",
    "section": "3.2 Functions",
    "text": "3.2 Functions\nFunctions are built-in commands that allow R users to run analyses. All functions require the definition of arguments within round brackets (). Each function requires different information and has different arguments that can be used to customise the analysis. A detailed list of these arguments and a description of the function can be found in the function’s associated help file.\n\n3.2.1 Help files\nEach function that exists within R has an associated help file. RStudio does not require an internet connection to access these help files if the function is available in the current session of R.\nTo retrieve help files, enter ? followed by the function name into the console window, e.g ?mean. The help file will appear in window D of the interface shown in the introduction.\nHelp files contain the following information:\n\nDescription: what the function is used for\nUsage: how the function is used\nArguments: required and optional arguments entered into round brackets necessary for the function to work\nDetails: relevant details about the function in question\nReferences\nSee also: links to other relevant functions\nExamples: example code with applications of the function\n\n\n\n3.2.2 Error and warning messages\nWhere a function or object has not been correctly specified, or their is some mistake in the syntax that has been sent to the console, R will return an error message. These messages are generally informative and include the location of the error.\nThe most common errors include misspelling functions or objects:\n\nsqrt(ojbect_1)\n\nError in eval(expr, envir, enclos): object 'ojbect_1' not found\n\nSqrt(object_1)\n\nError in Sqrt(object_1): could not find function \"Sqrt\"\n\n\nOr where an object has not yet been specified:\n\nplot(x, y)\n\nError in eval(expr, envir, enclos): object 'x' not found\n\n\nWhen R returns an error message, this means that the operation has been completely halted. R may also return warning messages which look similar to errors but does not necessarily mean the operation has been stopped.\nWarnings are included to indicate that R suspects something in the operation may be wrong and should be checked. There are occasions where warnings can be ignored but this is only after the operation has been checked.\n\n\n3.2.3 Cleaning the environment\nTo remove objects from the RStudio environment, we can use the rm function. This can be combined with the ls() function, which lists all objects in the environment, to remove all objects currently loaded:\n\nrm(list = ls())\n\n\n\n\n\n\n\nWarning\n\n\n\nThere are no undo and redo buttons for R syntax. The rm function will permanently delete objects from the environment. The only way to reverse this is to re-run the code that created the objects originally from the script file.",
    "crumbs": [
      "Introduction to R and RStudio",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>R objects, functions and packages</span>"
    ]
  },
  {
    "objectID": "objects_functions.html#packages",
    "href": "objects_functions.html#packages",
    "title": "3  R objects, functions and packages",
    "section": "3.3 Packages",
    "text": "3.3 Packages\nR packages are a collection of functions and datasets developed by R users that expand existing R capabilities or add completely new ones. Packages allow users to apply the most up-to-date methods shortly after they are developed, unlike other statistical software packages that require an entirely new version.\n\n3.3.1 Installing packages from CRAN\nThe quickest way to install a package in R is by using the install.packages function. This sends RStudio to the online repository of tested and verified R packages (known as CRAN) and downloads the package files onto the machine you are currently working from in temporary files. Ensure that the package you wish to install is spelled correctly and surrounded by ''.\n\n\n\n\n\n\nWarning\n\n\n\nThe install.packages function requires an internet connection, and can take a long time if the package has a lot of dependent packages that also need downloading.\nThis process should only be carried out the first time a package is used on a machine, or when a substantial update has taken place, to download the latest version of the package.\n\n\n\n\n3.3.2 Loading packages to an R session\nEvery time a new session of RStudio is opened, packages must be reloaded. To load a package into R (and gain access to the associated functions and data), use the library function.\nLoading a package does not require an internet connection, but will only work if the package has already been installed and saved onto the computer you are working from. If you are unsure, use the function installed.packages to return a list of all packages that are loaded onto the machine you are working from.\n\n\n\n\n\n\nStyle tip\n\n\n\nBegin any script file that requires packages by loading them into the current session. This ensures that there will be no error messages from functions that are not available in the current session.\n\n\n\n\n3.3.3 The pacman package\nThe pacman package is a set of package management functions which is designed to make tasks such as installing and loading packages simpler, and speeds up these processes. There are lots of useful functions included in this package, but the one that we will be using in this course is p_load.\np_load acts as a wrapper for the library function. It first checks the computer to see whether the package(s) listed is installed. If they are, p_load loads the package(s) into the current RStudio session. If not, it attempts to install the package(s) from the CRAN repository.\nIf you have never used the pacman package before, run the following code to ensure that it is installed on your machine:\n\ninstall.packages('pacman')",
    "crumbs": [
      "Introduction to R and RStudio",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>R objects, functions and packages</span>"
    ]
  },
  {
    "objectID": "open_explore_data.html",
    "href": "open_explore_data.html",
    "title": "4  Opening and exploring data",
    "section": "",
    "text": "4.1 Styles of R coding\nUp to this point, beyond the style tips sprinkled through these notes, we have not thought about the style of R coding we will be using. There are different approaches to R coding that we can use, they can be thought of as different dialects of the R programming language.\nThe choice of R ‘dialect’ depends on personal preference. Some prefer to use the ‘base R’ approach that does not rely on any packages that may need updating, making it a more stable approach. However, base R can be difficult to read for those not comfortable with coding.\nThe alternative approach that we will be adopting in this course is the ‘tidyverse’ approach. Tidyverse is a set of packages that have been designed to make R coding more readable and efficient. They have been designed with reproducibility in mind, which means there is a wealth of online (mostly free), well-written resources available to help use these packages. Tidyverse is also the preferred coding style of the Government Analysis Function guidance.\nIf you have not done so already, install the Tidyverse packages to your machine using the following code:\ninstall.packages('tidyverse')\nOnce the tidyverse package is installed, we must load it into the current working session. At the beginning of your script file add the following syntax:\npacman::p_load(tidyverse)",
    "crumbs": [
      "Tidyverse and data wrangling",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Opening and exploring data</span>"
    ]
  },
  {
    "objectID": "open_explore_data.html#styles-of-r-coding",
    "href": "open_explore_data.html#styles-of-r-coding",
    "title": "4  Opening and exploring data",
    "section": "",
    "text": "Warning\n\n\n\nThis can take a long time if you have never downloaded the tidyverse packages before as there are many dependencies that are required.\nDo not stress if you get a lot of text in the console! This is normal, but watch out for any error messages.\n\n\n\n\n\n\n\n\n\n\nStyle tip\n\n\n\nThe double colon in R can be used to run a function within an installed package without loading the entire package to an R session.",
    "crumbs": [
      "Tidyverse and data wrangling",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Opening and exploring data</span>"
    ]
  },
  {
    "objectID": "open_explore_data.html#the-working-directory",
    "href": "open_explore_data.html#the-working-directory",
    "title": "4  Opening and exploring data",
    "section": "4.2 The working directory",
    "text": "4.2 The working directory\nThe working directory is a file path on your computer that R sets as the default location when opening, saving, or exporting documents, files, and graphics. This file path can be specified manually but setting the working directory saves time and makes code more efficient.\nThe working directory can be set manually by using the Session -&gt; Set Working Directory -&gt; Change Directory… option from the drop-down menu, or the setwd function. Both options require the directory to be specified each time R is restarted, are sensitive to changes in folders within the file path, and cannot be used when script files are shared between colleagues.\nAn alternative approach that overcomes all these issues is to create an R project.\n\n4.2.1 R projects\nR projects are files (saved with the .Rproj extension) that keep associated files (including scripts, data, and outputs) grouped together. An R project automatically sets the working directory relative to its current location, which makes collaborative work easier, and avoids issues when a file path is changed.\nProjects are created by using the File -&gt; New project option from the drop-down menu, or using the  icon from the top-right corner of the RStudio interface. Existing projects can be opened under the File -&gt; Open project… drop-down menu or using the project icon.\nWhen creating a new project, we must choose whether we are creating a new directory or using an existing one. Usually, we will have already set up a folder containing data or other documents related to the analysis we plan to carry out. If this is the case, we are using an existing directory and selecting the analysis folder as the project directory.\n\n\n\n\n\n\nStyle tip\n\n\n\nHave a clear order to your analysis folder. Consider creating separate folders within a project for input and output data, documentation, and outputs such as graphs or tables.",
    "crumbs": [
      "Tidyverse and data wrangling",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Opening and exploring data</span>"
    ]
  },
  {
    "objectID": "open_explore_data.html#loading-data",
    "href": "open_explore_data.html#loading-data",
    "title": "4  Opening and exploring data",
    "section": "4.3 Loading data",
    "text": "4.3 Loading data\nTo ensure our code is collaborative and reproducible, we should strive to store data in formats that can be used across multiple platforms. One of the best ways to do this is to store data as a comma-separated file (.csv). CSV files can be opened by a range of different softwares (including R, SPSS, STATA and excel), and base R can be used to open these files without requiring additional packages.\nUnfortunately, we are not always able to choose the format that data are stored in. For example, the English Housing Survey (EHS) data is stored as a .sav (SPSS) data file. Fortunately for us, R has a wide range of packages that have been developed to load data from every conceivable format.\nThe package that we will be using the load SPSS data is the haven package. To ensure this is loaded in at the beginning of each session, adapt the previous p_load function:\n\npacman::p_load(tidyverse, haven)\n\nTo avoid any errors arising from spelling mistakes, we can use the list.files function, which returns a list of files and folders from the current working directory. The file names can be copied from the console and pasted into the script file. As the data are saved in a folder within the working directory, we add the argument path = to specify the folder we want to list files from.\n\nlist.files(path = \"data\")\n\n[1] \"Detailed_forecast_tables_Economy_March_2024.xlsx\"\n[2] \"generalfs21_EUL.sav\"                             \n[3] \"interviewfs21_EUL.sav\"                           \n\n\nThe first data set we will load is thegeneralfs21_EUL.sav file. This contains general information taken from the English Housing Survey (EHS) from 2021, including a unique identifier, the responders’ region, and the tenure type.\nThe EHS data can be loaded into R using the read_spss function, and saved as an object using the &lt;- symbol:\n\nehs_general &lt;- read_spss(file = \"data/generalfs21_EUL.sav\")\n\nThe imported data will appear in the environment with its given name. The contents of the object can be viewed by clicking on the object name in the environment, opening a tab next to script files. This window is a preview so cannot be edited here.\nSome useful functions that can be used to explore a dataset include:\n\n# Return variable names\nnames(ehs_general)\n\n[1] \"serialanon\" \"aagfh21\"    \"paired\"     \"tenure8x\"   \"tenure4x\"  \n[6] \"tenure2x\"   \"gorehs\"     \"region3x\"   \"govreg1\"   \n\n# Returns the first 6 rows\nhead(ehs_general)\n\n# A tibble: 6 × 9\n  serialanon  aagfh21   paired      tenure8x tenure4x tenure2x gorehs   region3x\n  &lt;dbl+lbl&gt;   &lt;dbl+lbl&gt; &lt;dbl+lbl&gt;   &lt;dbl+lb&gt; &lt;dbl+lb&gt; &lt;dbl+lb&gt; &lt;dbl+lb&gt; &lt;dbl+lb&gt;\n1 20220000001 3934.     1 [Paired]  1 [owne… 1 [owne… 1 [Priv…  7 [Eas… 3 [Rest…\n2 20220000005 1580.     1 [Paired]  1 [owne… 1 [owne… 1 [Priv… 10 [Sou… 3 [Rest…\n3 20220000006 3360.     1 [Paired]  1 [owne… 1 [owne… 1 [Priv…  6 [Wes… 3 [Rest…\n4 20220000012 1368.     0 [Not pai… 1 [owne… 1 [owne… 1 [Priv…  5 [Eas… 3 [Rest…\n5 20220000013 9847.     1 [Paired]  1 [owne… 1 [owne… 1 [Priv… 10 [Sou… 3 [Rest…\n6 20220000017 3262.     0 [Not pai… 1 [owne… 1 [owne… 1 [Priv…  6 [Wes… 3 [Rest…\n# ℹ 1 more variable: govreg1 &lt;dbl+lbl&gt;\n\n# Returns the last 6 rows\ntail(ehs_general)\n\n# A tibble: 6 × 9\n  serialanon  aagfh21   paired      tenure8x tenure4x tenure2x gorehs   region3x\n  &lt;dbl+lbl&gt;   &lt;dbl+lbl&gt; &lt;dbl+lbl&gt;   &lt;dbl+lb&gt; &lt;dbl+lb&gt; &lt;dbl+lb&gt; &lt;dbl+lb&gt; &lt;dbl+lb&gt;\n1 20220031393  262.     0 [Not pai… 3 [loca… 3 [loca… 2 [Soci…  7 [Eas… 3 [Rest…\n2 20220031396 5741.     1 [Paired]  1 [owne… 1 [owne… 1 [Priv…  6 [Wes… 3 [Rest…\n3 20220031401 1579.     0 [Not pai… 1 [owne… 1 [owne… 1 [Priv…  6 [Wes… 3 [Rest…\n4 20220031402 2178.     0 [Not pai… 1 [owne… 1 [owne… 1 [Priv…  9 [Sou… 2 [Lond…\n5 20220031408 1133.     1 [Paired]  1 [owne… 1 [owne… 1 [Priv… 10 [Sou… 3 [Rest…\n6 20220031409 1879.     1 [Paired]  1 [owne… 1 [owne… 1 [Priv… 10 [Sou… 3 [Rest…\n# ℹ 1 more variable: govreg1 &lt;dbl+lbl&gt;\n\n# Gives information about the structure of an object (including variable types)\nstr(ehs_general)\n\ntibble [9,752 × 9] (S3: tbl_df/tbl/data.frame)\n $ serialanon: dbl+lbl [1:9752] 2.02e+10, 2.02e+10, 2.02e+10, 2.02e+10, 2.02e+10, 2.0...\n   ..@ label        : chr \"Key variable: unique archived identifier\"\n   ..@ format.spss  : chr \"F11.0\"\n   ..@ display_width: int 13\n   ..@ labels       : Named num [1:2] -9 -8\n   .. ..- attr(*, \"names\")= chr [1:2] \"Does not apply\" \"No Answer\"\n $ aagfh21   : dbl+lbl [1:9752] 3934, 1580, 3360, 1368, 9847, 3262, 6584,  389, 4193,...\n   ..@ label        : chr \"Household weight 2021\"\n   ..@ format.spss  : chr \"F8.2\"\n   ..@ display_width: int 10\n   ..@ labels       : Named num [1:2] -9 -8\n   .. ..- attr(*, \"names\")= chr [1:2] \"Does not apply\" \"No answer\"\n $ paired    : dbl+lbl [1:9752] 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1,...\n   ..@ label      : chr \"Whether paired sample case\"\n   ..@ format.spss: chr \"F3.0\"\n   ..@ labels     : Named num [1:4] -9 -8 0 1\n   .. ..- attr(*, \"names\")= chr [1:4] \"Does not apply\" \"No Answer\" \"Not paired\" \"Paired\"\n $ tenure8x  : dbl+lbl [1:9752] 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 4, 1, 4, 1, 1, 2, 4,...\n   ..@ label        : chr \"Tenure with vacancy\"\n   ..@ format.spss  : chr \"F2.0\"\n   ..@ display_width: int 10\n   ..@ labels       : Named num [1:10] -9 -8 1 2 3 4 5 6 7 8\n   .. ..- attr(*, \"names\")= chr [1:10] \"Does not apply\" \"No Answer\" \"owner occupied - occupied\" \"private rented - occupied\" ...\n $ tenure4x  : dbl+lbl [1:9752] 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 4, 1, 4, 1, 1, 2, 4,...\n   ..@ label        : chr \"Tenure\"\n   ..@ format.spss  : chr \"F2.0\"\n   ..@ display_width: int 10\n   ..@ labels       : Named num [1:6] -9 -8 1 2 3 4\n   .. ..- attr(*, \"names\")= chr [1:6] \"Does not apply\" \"No Answer\" \"owner occupied\" \"private rented\" ...\n $ tenure2x  : dbl+lbl [1:9752] 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 2,...\n   ..@ label        : chr \"Tenure\"\n   ..@ format.spss  : chr \"F2.0\"\n   ..@ display_width: int 10\n   ..@ labels       : Named num [1:4] -9 -8 1 2\n   .. ..- attr(*, \"names\")= chr [1:4] \"Does not apply\" \"No Answer\" \"Private\" \"Social\"\n $ gorehs    : dbl+lbl [1:9752]  7, 10,  6,  5, 10,  6,  4, 10,  7,  2, 10,  2,  2,  ...\n   ..@ label      : chr \"Government Office Region EHS version\"\n   ..@ format.spss: chr \"F2.0\"\n   ..@ labels     : Named num [1:11] -9 -8 1 2 4 5 6 7 8 9 ...\n   .. ..- attr(*, \"names\")= chr [1:11] \"Does not apply\" \"No answer\" \"North East\" \"North West\" ...\n $ region3x  : dbl+lbl [1:9752] 3, 3, 3, 3, 3, 3, 1, 3, 3, 1, 3, 1, 1, 3, 1, 2, 3, 1,...\n   ..@ label        : chr \"Overall region of England\"\n   ..@ format.spss  : chr \"F2.0\"\n   ..@ display_width: int 10\n   ..@ labels       : Named num [1:5] -9 -8 1 2 3\n   .. ..- attr(*, \"names\")= chr [1:5] \"Does not apply\" \"No Answer\" \"Northern regions\" \"London and South East regions\" ...\n $ govreg1   : dbl+lbl [1:9752] 4, 4, 2, 2, 4, 2, 1, 4, 4, 1, 4, 1, 1, 2, 1, 4, 4, 1,...\n   ..@ label        : chr \"Government office Region, grouped\"\n   ..@ format.spss  : chr \"F2.0\"\n   ..@ display_width: int 9\n   ..@ labels       : Named num [1:6] -9 -8 1 2 3 4\n   .. ..- attr(*, \"names\")= chr [1:6] \"Does not apply\" \"No Answer\" \"North\" \"Midlands\" ...\n - attr(*, \"notes\")= chr [1:6] \"This third delivery file (interviewfs21.sav)\" \"was updated on 29/11/22\" \"   (Entered 01-Dec-2022)\" \"This third delivery file (interviewfs21.sav)\" ...\n\n\nThe str function tells us that this object is a tibble. This is tidyverse language for a data set (in base R, it is known as a data.frame). All variables are recognised as dbl + lbl, or labelled double variables. Double is tidyverse language for numeric data, and labels are taken from the original SPSS data.\nIt is important to check that R has correctly recognised variable type when data are loaded, before generating any visualisations or analysis. If variables are incorrectly specified, this could either lead to errors or invalid analyses. We will see how to change variables types later in this chapter.\nThe variables in this tibble contain additional information, stored as attributes. Data imported from other sources do not typically include these attributes by default, but these are able to uphold any information that was stored in the ‘Variable view’ window of SPSS.",
    "crumbs": [
      "Tidyverse and data wrangling",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Opening and exploring data</span>"
    ]
  },
  {
    "objectID": "open_explore_data.html#selecting-variables",
    "href": "open_explore_data.html#selecting-variables",
    "title": "4  Opening and exploring data",
    "section": "4.4 Selecting variables",
    "text": "4.4 Selecting variables\nOften, we will not need every variable in a downloaded dataset to carry out an analysis, and we may wish to create a smaller analysis tibble. We may also wish to select individual variables from the tibble to apply functions to them without including the entire dataset.\nTo select one or more variable and return them as a new tibble, we can use the select function from tidyverse’s dplyr package.\nFor example, we do not need all the variables contained in the EHS general dataset. The variables we are interested in keeping are the unique identifier variables (serialanon), the survey weights (aagfh21), the tenure type response with 4 options (tenure4x), and the Government office region (govreg1):\n\n# Variables can be selected using their names\nselect(ehs_general, serialanon, aagfh21, tenure4x, gorehs)\n\n# A tibble: 9,752 × 4\n   serialanon  aagfh21   tenure4x           gorehs                       \n   &lt;dbl+lbl&gt;   &lt;dbl+lbl&gt; &lt;dbl+lbl&gt;          &lt;dbl+lbl&gt;                    \n 1 20220000001 3934.     1 [owner occupied]  7 [East]                    \n 2 20220000005 1580.     1 [owner occupied] 10 [South West]              \n 3 20220000006 3360.     1 [owner occupied]  6 [West Midlands]           \n 4 20220000012 1368.     1 [owner occupied]  5 [East Midlands]           \n 5 20220000013 9847.     1 [owner occupied] 10 [South West]              \n 6 20220000017 3262.     1 [owner occupied]  6 [West Midlands]           \n 7 20220000022 6584.     1 [owner occupied]  4 [Yorkshire and the Humber]\n 8 20220000025  389.     1 [owner occupied] 10 [South West]              \n 9 20220000026 4193.     2 [private rented]  7 [East]                    \n10 20220000027 3589.     1 [owner occupied]  2 [North West]              \n# ℹ 9,742 more rows\n\n# Or their column number\nselect(ehs_general, 1, 2, 5, 7)\n\n# A tibble: 9,752 × 4\n   serialanon  aagfh21   tenure4x           gorehs                       \n   &lt;dbl+lbl&gt;   &lt;dbl+lbl&gt; &lt;dbl+lbl&gt;          &lt;dbl+lbl&gt;                    \n 1 20220000001 3934.     1 [owner occupied]  7 [East]                    \n 2 20220000005 1580.     1 [owner occupied] 10 [South West]              \n 3 20220000006 3360.     1 [owner occupied]  6 [West Midlands]           \n 4 20220000012 1368.     1 [owner occupied]  5 [East Midlands]           \n 5 20220000013 9847.     1 [owner occupied] 10 [South West]              \n 6 20220000017 3262.     1 [owner occupied]  6 [West Midlands]           \n 7 20220000022 6584.     1 [owner occupied]  4 [Yorkshire and the Humber]\n 8 20220000025  389.     1 [owner occupied] 10 [South West]              \n 9 20220000026 4193.     2 [private rented]  7 [East]                    \n10 20220000027 3589.     1 [owner occupied]  2 [North West]              \n# ℹ 9,742 more rows\n\n\nThe select function can also be combined with a number of ‘selection helper’ functions that help us select variables based on naming conventions:\n\nstarts_with(\"xyz\") returns all variables with names beginning xyz\nends_with(\"xyz\") returns all variables with names ending xyz\ncontains(\"xyz\") returns all variables that have xyz within their name\n\nOr based on whether they match a condition:\n\nwhere(is.numeric) returns all variables that are classed as numeric\n\nFor a full list of these selection helpers, access the helpfile using ?tidyr_tidy_select.\nThe select function can also be used to remove variables from a tibble by adding a - before the variable name or number. For example, to return the EHS general dataset without the unique identifier variable, we use:\n\nselect(ehs_general, -serialanon)\n\n# A tibble: 9,752 × 8\n   aagfh21   paired         tenure8x tenure4x tenure2x gorehs   region3x govreg1\n   &lt;dbl+lbl&gt; &lt;dbl+lbl&gt;      &lt;dbl+lb&gt; &lt;dbl+lb&gt; &lt;dbl+lb&gt; &lt;dbl+lb&gt; &lt;dbl+lb&gt; &lt;dbl+l&gt;\n 1 3934.     1 [Paired]     1 [owne… 1 [owne… 1 [Priv…  7 [Eas… 3 [Rest… 4 [Res…\n 2 1580.     1 [Paired]     1 [owne… 1 [owne… 1 [Priv… 10 [Sou… 3 [Rest… 4 [Res…\n 3 3360.     1 [Paired]     1 [owne… 1 [owne… 1 [Priv…  6 [Wes… 3 [Rest… 2 [Mid…\n 4 1368.     0 [Not paired] 1 [owne… 1 [owne… 1 [Priv…  5 [Eas… 3 [Rest… 2 [Mid…\n 5 9847.     1 [Paired]     1 [owne… 1 [owne… 1 [Priv… 10 [Sou… 3 [Rest… 4 [Res…\n 6 3262.     0 [Not paired] 1 [owne… 1 [owne… 1 [Priv…  6 [Wes… 3 [Rest… 2 [Mid…\n 7 6584.     0 [Not paired] 1 [owne… 1 [owne… 1 [Priv…  4 [Yor… 1 [Nort… 1 [Nor…\n 8  389.     0 [Not paired] 1 [owne… 1 [owne… 1 [Priv… 10 [Sou… 3 [Rest… 4 [Res…\n 9 4193.     1 [Paired]     2 [priv… 2 [priv… 1 [Priv…  7 [Eas… 3 [Rest… 4 [Res…\n10 3589.     1 [Paired]     1 [owne… 1 [owne… 1 [Priv…  2 [Nor… 1 [Nort… 1 [Nor…\n# ℹ 9,742 more rows\n\n\nAfter making changes to the analysis dataset, it is useful to save this data separately to the original raw data. This can be done using the write_csv function.\n\nehs_general_reduced &lt;- select(ehs_general, serialanon, aagfh21, tenure4x, gorehs)\n\n\nwrite_csv(ehs_general_reduced, file = \"saved_data/ehs_general_reduced.csv\")\n\n\n\n\n\n\n\nWarning\n\n\n\nWhen saving updated tibbles as files, use a different file name to the original raw data. Using the same name will overwrite the original file. We always want a copy of the original in case of any errors or issues.\n\n\nThe select function returns variables as a tibble object. However, some functions, for example summary functions from base R, require data in the form of a vector. Vectors are lists of values with no formal structure, unlike a tibble which is structured to have rows and columns. To return a single variable as a vector, we can use the $ symbol between the data name and the variable to return:\n\nehs_general_reduced$aagfh21",
    "crumbs": [
      "Tidyverse and data wrangling",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Opening and exploring data</span>"
    ]
  },
  {
    "objectID": "open_explore_data.html#filtering-data",
    "href": "open_explore_data.html#filtering-data",
    "title": "4  Opening and exploring data",
    "section": "4.5 Filtering data",
    "text": "4.5 Filtering data\nThe filter function, from tidyverse’s dplyr package allows us to return subgroups of the data based on conditional statements. These conditional statements can include mathematical operators:\n\n&lt;= less than or equal to,\n&lt; less than,\n&gt;= greater than or equal to,\n&gt; greater than,\n== is equal to,\n!= is not equal to,\n\nor can be based on conditional functions:\n\nis.na(variable) where variable is missing, #\nbetween(variable, a, b) where variable lies between a and b.\n\nA list of these conditional statements can be found in the help file using ?filter.\nFor example, we may wish to return rows from the EHS dataset that were privately rented. To check which number refers to privately rented, we can check the labels attribute of the tenure4x variable which shows the labels from the SPSS file:\n\nattributes(ehs_general_reduced$tenure4x)$labels\n\n     Does not apply           No Answer      owner occupied      private rented \n                 -9                  -8                   1                   2 \n    local authority housing association \n                  3                   4 \n\n\nPrivate rented is given by a 2 in the current dataset, therefore our conditional statement will return rows where the tenure4x variable takes the value 2.\n\nfilter(ehs_general_reduced, tenure4x == 2)\n\n# A tibble: 1,735 × 4\n   serialanon  aagfh21   tenure4x           gorehs                       \n   &lt;dbl+lbl&gt;   &lt;dbl+lbl&gt; &lt;dbl+lbl&gt;          &lt;dbl+lbl&gt;                    \n 1 20220000026 4193.     2 [private rented]  7 [East]                    \n 2 20220000039  423.     2 [private rented]  7 [East]                    \n 3 20220000075 1017.     2 [private rented]  7 [East]                    \n 4 20220000092 1554.     2 [private rented]  7 [East]                    \n 5 20220000113 5254.     2 [private rented]  8 [London]                  \n 6 20220000132 7609.     2 [private rented]  4 [Yorkshire and the Humber]\n 7 20220000134  775.     2 [private rented]  5 [East Midlands]           \n 8 20220000135 1313.     2 [private rented]  1 [North East]              \n 9 20220000187 1528.     2 [private rented]  8 [London]                  \n10 20220000198  557.     2 [private rented] 10 [South West]              \n# ℹ 1,725 more rows\n\n\nMultiple conditional statements can be added to the same function by separating them with a comma , where we want all conditions met, or the | in place of or. To return all respondents that lived in privately rented accommodation in the North East, we can extend the previous filter statement:\n\nattributes(ehs_general_reduced$gorehs)$labels\n\n          Does not apply                No answer               North East \n                      -9                       -8                        1 \n              North West Yorkshire and the Humber            East Midlands \n                       2                        4                        5 \n           West Midlands                     East                   London \n                       6                        7                        8 \n              South East               South West \n                       9                       10 \n\n# North East is region 1\nfilter(ehs_general_reduced, tenure4x == 2, gorehs == 1)\n\n# A tibble: 76 × 4\n   serialanon  aagfh21   tenure4x           gorehs        \n   &lt;dbl+lbl&gt;   &lt;dbl+lbl&gt; &lt;dbl+lbl&gt;          &lt;dbl+lbl&gt;     \n 1 20220000135  1313.    2 [private rented] 1 [North East]\n 2 20220001633  3849.    2 [private rented] 1 [North East]\n 3 20220002101  1016.    2 [private rented] 1 [North East]\n 4 20220002817   323.    2 [private rented] 1 [North East]\n 5 20220003959  2800.    2 [private rented] 1 [North East]\n 6 20220004183   636.    2 [private rented] 1 [North East]\n 7 20220005151 10707.    2 [private rented] 1 [North East]\n 8 20220005393  2189.    2 [private rented] 1 [North East]\n 9 20220005697  2059.    2 [private rented] 1 [North East]\n10 20220005754   625.    2 [private rented] 1 [North East]\n# ℹ 66 more rows",
    "crumbs": [
      "Tidyverse and data wrangling",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Opening and exploring data</span>"
    ]
  },
  {
    "objectID": "open_explore_data.html#pipes",
    "href": "open_explore_data.html#pipes",
    "title": "4  Opening and exploring data",
    "section": "4.6 Pipes",
    "text": "4.6 Pipes\nWhen creating an analysis-ready dataset, we often want to combine functions such as select and filter. Previously, these would need to be carried out separately and a new object would need to be created or overwritten at each step, clogging up the environment.\nIn tidyverse, we combine functions within a single process using the ‘pipe’ symbol %&gt;%, which is read as ‘and then’ within the code. For example, if we wanted to just select the unique identifiers of respondents that were privately renting in the North East, we could do this in a single process:\n\nehs_general_reduced %&gt;% \n  filter(tenure4x == 2, gorehs == 1) %&gt;% \n  select(serialanon)\n\n# A tibble: 76 × 1\n   serialanon \n   &lt;dbl+lbl&gt;  \n 1 20220000135\n 2 20220001633\n 3 20220002101\n 4 20220002817\n 5 20220003959\n 6 20220004183\n 7 20220005151\n 8 20220005393\n 9 20220005697\n10 20220005754\n# ℹ 66 more rows\n\n\n\n\n\n\n\n\nStyle tips\n\n\n\nWhen combining multiple functions within a process using pipes, it is good practice to start the code with the data and pipe that into the functions, rather than including it in the function itself.\n\n\n\n\n\n\n\n\nHelpful hint\n\n\n\nRather than typing out pipes every time, use the keyboard shortcut ctrl + shift + m for Windows and Command + shift + m for Mac.",
    "crumbs": [
      "Tidyverse and data wrangling",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Opening and exploring data</span>"
    ]
  },
  {
    "objectID": "open_explore_data.html#creating-new-variables",
    "href": "open_explore_data.html#creating-new-variables",
    "title": "4  Opening and exploring data",
    "section": "4.7 Creating new variables",
    "text": "4.7 Creating new variables\nThe function mutate from tidyverse’s dplyr package allows us to add new variables to a dataset. We can add multiple variables within the same function, separating each with a comma ,.\nThe mutate function is helpful when variable types are not correctly specified by R when they are read in. For example, the region and tenancy type variables in the ehs_general_reduced tibble are categorical variables but are currently recognised as numeric.\nCategorical variables in R are known as factors. These factors can be ordered and can have labels assigned to different levels. To convert an existing variable to a factor, we can use the factor or as_factor functions. Here, we can combine the mutate and as_factor functions to convert tenancy type and region to factors:\n\nehs_general_reduced &lt;- mutate(ehs_general_reduced,\n                              tenancy_type = as_factor(tenure4x),\n                              region = as_factor(gorehs))\n\n\n\n\n\n\n\nNote\n\n\n\nAs this data was taken from an SPSS file that had labels attached to the grouped variables, we do not need to specify these within the as_factor function.\nWhen the variables do not have this labelling structure already, they will need to be added using the label argument of the factor function (see ?factor for more information).\n\n\nThe mutate function can also be used to convert numeric variables into an ordered categorical variable, and can be used to transform variables using mathematical functions. For example, we can create two new variables, first giving the square root of the weighting variable, and second grouping the weighting variable into three categories (low: \\(&lt; 1000\\), medium: \\(1000 \\leq\\) aagfh21 \\(&lt; 5000\\), high: \\(\\geq 5000\\)):\n\nehs_general_reduced &lt;- mutate(ehs_general_reduced,\n                              weighting_sqrt = sqrt(aagfh21),\n                              weighting_fct = cut(aagfh21, \n                                                  breaks = c(0, 1000, 5000, Inf),\n                                                  right = TRUE,\n                                                  labels = c(\"Low\", \"Medium\",\n                                                              \"High\")))\n\n\n\n\n\n\n\nHelpful hint\n\n\n\nThe c function takes a list of values separated by commas and returns them as a vector. This is useful when a function argument requires multiple values (and we don’t want R to move onto the next argument, which is what a comma inside functions usually means).",
    "crumbs": [
      "Tidyverse and data wrangling",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Opening and exploring data</span>"
    ]
  },
  {
    "objectID": "open_explore_data.html#other-useful-dplyr-functions",
    "href": "open_explore_data.html#other-useful-dplyr-functions",
    "title": "4  Opening and exploring data",
    "section": "4.8 Other useful dplyr functions",
    "text": "4.8 Other useful dplyr functions\nTo ensure our code follows the tidyverse style guide, variable names should be concise, informative, and contain no special charaters (other than _). The original variable names given in the original EHS data were definitely not stylish! To change names in a dataset, we can use the rename function:\n\nehs_general_reduced &lt;- rename(ehs_general_reduced,\n                              id = serialanon,\n                              weighting = aagfh21)\n\nFor more useful data exploration and manipulation functions from the dplyr package, I would recommending taking a look at the vignette associated with the package (a long-form version of a help file):\nvignette(\"dplyr\")\nOr look at the dplyr cheatsheet.",
    "crumbs": [
      "Tidyverse and data wrangling",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Opening and exploring data</span>"
    ]
  },
  {
    "objectID": "open_explore_data.html#a-smooth-process-to-the-analysis-dataset",
    "href": "open_explore_data.html#a-smooth-process-to-the-analysis-dataset",
    "title": "4  Opening and exploring data",
    "section": "4.9 A smooth process to the analysis dataset",
    "text": "4.9 A smooth process to the analysis dataset\nOur EHS analysis dataset has been created haphazardly through this chapter to demostrate each step separately. In reality, we would load this data and manipulate it in one process, separating steps by pipes %&gt;%.\nThe code below takes the data from its saw form (the .sav file) and transforms it into a clean dataset that we will be using for the rest of the course:\n\n# Step 1: load the dataset into R and attach as an object\nehs_general_tidy &lt;- read_spss(file = \"Data/generalfs21_EUL.sav\") %&gt;% \n# Step 2: convert grouping variables into factors\n                    mutate(tenure_type = as_factor(tenure4x),\n                           region = as_factor(gorehs)) %&gt;% \n# Step 3: rename other variables to avoid confusion\n                    rename(id = serialanon,\n                           weighting = aagfh21) %&gt;% \n# Step 4: keep only the necessary variables\n                    select(id, weighting, tenure_type, region)\n\n# Check the new data looks correct\nstr(ehs_general_tidy)\n\n# Step 5: save this tidy data as a new file in a saved_data folder\nwrite_csv(ehs_general_tidy, file = \"saved_data/ehs_general_tidy.csv\")",
    "crumbs": [
      "Tidyverse and data wrangling",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Opening and exploring data</span>"
    ]
  },
  {
    "objectID": "open_explore_data.html#exercise-3",
    "href": "open_explore_data.html#exercise-3",
    "title": "4  Opening and exploring data",
    "section": "Exercise 3",
    "text": "Exercise 3\n\nYou have been provided with another .sav file which contains the interview responses from the EHS. Create and save a tidy version of this dataset, ensuring variables are classified as the correct type and names follow the style conventions (if you cannot remember these, check here for a reminder).\n\nThe variables we need in the tidy dataset are:\n\nThe unique identifier serialanon\nThe gross household income HYEARGRx\nThe length of residence lenresb\nThe weekly rent rentwkx and mortgage mortwkx payments\nWhether the property is freehold or leasehold freeLeas\n\n\nSave the tidy interview dataset as a csv file with an appropriate file name.\nUsing the new, tidy dataset, answer the following questions:\n\n\nHow many respondents paid weekly rent of between £150 and £300?\nHow many respondents did not give a response to either the weekly rent or weekly mortgage question?\nWhat is the highest household gross income of these responders?",
    "crumbs": [
      "Tidyverse and data wrangling",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Opening and exploring data</span>"
    ]
  },
  {
    "objectID": "combining_summarising.html",
    "href": "combining_summarising.html",
    "title": "5  Combining and summarising datasets",
    "section": "",
    "text": "5.1 Combining multiple datasets\nBoth the SPSS datasets we have been working with so far have contained different information about the English Housing Survey (EHS). We will join these together to create a single analysis dataset with all the information we need.\nFirst we need to reload the tidy datasets we saved previously (now using the read_csv function):\nehs_general_tidy &lt;- read_csv(\"saved_data/ehs_general_tidy.csv\")\n\nRows: 9752 Columns: 4\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (2): tenure_type, region\ndbl (2): id, weighting\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nehs_interview_tidy &lt;- read_csv(\"saved_data/ehs_interview_tidy.csv\")\n\nRows: 9752 Columns: 6\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (2): length_residence, freehold_leasehold\ndbl (4): id, gross_income, weekly_rent, weekly_mortgage\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\nNotice that by default, the variables that were classed as factors have been recognised by R as chr (character). This is because CSV files are unable to store the grouping attributes that were created in R. Therefore, when we load in CSV files, we need to use the mutate function to re-classify these variables.\nWhen we need to apply the same function to a group of variables within a dataset, the mutate function can be combined with across, which uses selection helpers (see ?dplyr_tidy_select) and retains the original variable names\nehs_general_tidy &lt;- read_csv(\"saved_data/ehs_general_tidy.csv\") %&gt;% \n  mutate(across(where(is.character), factor))\n\n\nehs_interview_tidy &lt;- read_csv(\"saved_data/ehs_interview_tidy.csv\") %&gt;% \n  mutate(across(where(is.character), factor))\nJoining datasets can be carried out using join functions. There are 4 options we can choose from depending on which observations we want to keep if not all of them are matched (see ?full_join for a full list of options).\nIn this example, we want to keep all observations, even if they are missing from one of the datasets. This requires the full_join function. Both datasets contain a unique identifier which can be included in the full_join function to ensure we are joining like-for-like:\nehs_tidy &lt;- full_join(ehs_general_tidy, ehs_interview_tidy,\n                      by = \"id\") \n\nhead(ehs_tidy)\n\n# A tibble: 6 × 9\n       id weighting tenure_type region gross_income length_residence weekly_rent\n    &lt;dbl&gt;     &lt;dbl&gt; &lt;fct&gt;       &lt;fct&gt;         &lt;dbl&gt; &lt;fct&gt;                  &lt;dbl&gt;\n1 2.02e10     3934. owner occu… East         38378. 20-29 years               NA\n2 2.02e10     1580. owner occu… South…       26525  30+ years                 NA\n3 2.02e10     3360. owner occu… West …       25272. 10-19 years               NA\n4 2.02e10     1368. owner occu… East …       51280. 3-4 years                 NA\n5 2.02e10     9847. owner occu… South…       14365  30+ years                 NA\n6 2.02e10     3262. owner occu… West …       38955  30+ years                 NA\n# ℹ 2 more variables: weekly_mortgage &lt;dbl&gt;, freehold_leasehold &lt;fct&gt;",
    "crumbs": [
      "Tidyverse and data wrangling",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Combining and summarising datasets</span>"
    ]
  },
  {
    "objectID": "combining_summarising.html#combining-multiple-datasets",
    "href": "combining_summarising.html#combining-multiple-datasets",
    "title": "5  Combining and summarising datasets",
    "section": "",
    "text": "Style tips\n\n\n\nWhen writing script files, we want our code to be as concise and efficient as possible. Although we could use mutate to apply the factor function to each of the categorical variables, using the wrapper across reduces the amount of code needed and, consequently, the risk of errors.",
    "crumbs": [
      "Tidyverse and data wrangling",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Combining and summarising datasets</span>"
    ]
  },
  {
    "objectID": "combining_summarising.html#summarising-data",
    "href": "combining_summarising.html#summarising-data",
    "title": "5  Combining and summarising datasets",
    "section": "5.2 Summarising data",
    "text": "5.2 Summarising data\nSummary tables can be created using the summarise function. This returns tables in a tibble format, meaning they can easily be customised and exported as CSV files (using the write_csv function).\nThe summarise function is set up similarly to the mutate function: summaries are listed and given variable names, separated by a comma. The difference between these functions is that summarise collapses the tibble into a single summary, and the new variables must be created using a summary function.\nCommon examples of summary functions include:\n\nmean: a measure of centre when data are normally distributed\nmedian: a measure of centre, whatever the distribution\nrange: the minimum and maximum values\nmin: minimum\nmax: maximum\nIQR: interquartile range, gives the range of the middle 50% of the sample\nsd: standard deviation, a measure of the spread when data are normally distributed\nsum\nn: the number of rows the summary is calculated from\n\nFor example, if we want to generate summaries of the gross household income using the entire dataset:\n\nsummarise(ehs_tidy,\n          total_income = sum(gross_income),\n          median_income = median(gross_income),\n          n_rows = n())\n\n# A tibble: 1 × 3\n  total_income median_income n_rows\n         &lt;dbl&gt;         &lt;dbl&gt;  &lt;int&gt;\n1   397744132.        34016.   9752\n\n\nThe summarise function can be used to produce grouped summaries. This is done by first grouping the data with the group_by function.\n\n\n\n\n\n\nWarning\n\n\n\nWhenever using group_by, make sure to ungroup the data before proceeding. The grouping structure can be large and slow analysis, or may interact with other functions to produce unexpected results.\n\n\nFor example, we can expand the gross income summary table to show these summaries separated by region:\n\nehs_tidy %&gt;% \n  group_by(region) %&gt;% \n  summarise(total_income = sum(gross_income),\n            median_income = median(gross_income),\n            n_rows = n()) %&gt;% \n  ungroup()\n\n# A tibble: 9 × 4\n  region                   total_income median_income n_rows\n  &lt;fct&gt;                           &lt;dbl&gt;         &lt;dbl&gt;  &lt;int&gt;\n1 East                        55188890.        37225    1275\n2 East Midlands               31706518.        32453     806\n3 London                      59369895.        42278.   1199\n4 North East                  15381138.        26324.    474\n5 North West                  51011810.        29642    1410\n6 South East                  72646076.        39087.   1600\n7 South West                  44236539.        34958.   1105\n8 West Midlands               32522051.        30984.    878\n9 Yorkshire and the Humber    35681216.        29900    1005\n\n\nBefore creating summary tables, it is important to consider the most appropriate choice of summary statistics for your data.\n\n5.2.1 Summarising categorical data\nTo summarise a single categorical variable, we simply need to quantify the distribution of observations lying in each group. The simplest way to do this is to count the number of observations that lie in each group. However, a simple count can be difficult to interpret without proper context. Often, we wish to present these counts relative to the total sample that they are taken from.\nThe proportion of observations in a given group is estimated as the number in the group divided by the total sample size. This gives a value between 0 and 1. Multiplying the proportion by 100 will give the percentage in each group, taking the value between 0 and 100%.\nFor example, to calculate the proportion of respondents that live in privately rented properties, we divide the total number in that group by the total number of respondents:\n\nehs_tidy %&gt;% \n  # First group the data by tenure type\n  group_by(tenure_type) %&gt;% \n  # Then count the number of rows in each of these group (types)\n  summarise(n_tenancy = n()) %&gt;% \n  # Be sure to ungroup to remove this structure!\n  ungroup() %&gt;% \n  # Now calculate the total number of respondents overall \n  mutate(n_responses = sum(n_tenancy),\n  # and divide the group total by the overall total\n         prop_tenure = n_tenancy / n_responses)\n\n# A tibble: 4 × 4\n  tenure_type         n_tenancy n_responses prop_tenure\n  &lt;fct&gt;                   &lt;int&gt;       &lt;int&gt;       &lt;dbl&gt;\n1 housing association      1429        9752      0.147 \n2 local authority           971        9752      0.0996\n3 owner occupied           5617        9752      0.576 \n4 private rented           1735        9752      0.178 \n\n\nFrom this summary table, the proportion of responders that lived in privately rented properties was 0.178. To convert this into a percentage, we multiple the proportions by 100%:\n\nehs_tidy %&gt;% \n  # First group the data by tenure type\n  group_by(tenure_type) %&gt;% \n  # Then count the number of rows in each of these group (types)\n  summarise(n_tenancy = n()) %&gt;% \n  # Be sure to ungroup to remove this structure!\n  ungroup() %&gt;% \n  # Now calculate the total number of respondents overall \n  mutate(n_responses = sum(n_tenancy),\n  # and divide the group total by the overall total\n         prop_tenure = n_tenancy / n_responses,\n         perc_tenure = prop_tenure * 100)\n\n# A tibble: 4 × 5\n  tenure_type         n_tenancy n_responses prop_tenure perc_tenure\n  &lt;fct&gt;                   &lt;int&gt;       &lt;int&gt;       &lt;dbl&gt;       &lt;dbl&gt;\n1 housing association      1429        9752      0.147        14.7 \n2 local authority           971        9752      0.0996        9.96\n3 owner occupied           5617        9752      0.576        57.6 \n4 private rented           1735        9752      0.178        17.8 \n\n\nTherefore, 17.8% of responders lived in privately rented properties.\n\n\n5.2.2 Summarising numeric variables\nNumeric variables are typically summarised using the centre of the variable, also known as the average, and a measure of the spread of the variable. The most appropriate choice of summary statistics will depend on the distribution of the variable. More specifically, whether the numeric variable is normally distributed or not. The shape/distribution of a variable is typically investigated by plotting data in a histogram.\n\nMeasures of centre\nThe average of a numeric variable is another way of saying the centre of its distribution. Often, people will think of the mean when trying to calculate an average, however this may not always be the case.\n\n\n\n\n\n\n\n\n\nWhen data are normally distributed, the mean is the central peak of the distribution. This is calculated by adding together all numbers in the sample and dividing it by the sample size.\nHowever, when the sample is not normally distributed and the peak does not lie in the middle, extreme values or a longer tail will pull the mean towards it. Where data are not normally distributed, the mean will not be the centre and the value will be invalid. When this is the case, the median should be used instead. The median is calculated by ordering the numeric values from smallest to largest and selecting the middle value.\nWhen data are normally distributed, the mean and median will give the same, or very similar, values. This is because both are measuring the centre. However, when the data are skewed, the mean and median will differ. We prefer to use the mean where possible as it is the more powerful measure. This means that it uses more of the data than the median and is therefore more sensitive to changes in the sample.\n\n\nMeasures of spread\nGenerally the measure of the spread of a numeric variable is presented with a measure of spread, or how wide/narrow the distribution is. As with the apread, the most appropriate values will depend on whether the sample is normally distributed or not.\nThe most simple measure of spread is the range of a sample. In R, this is given as two values: the minimum and the maximum.\nThe issue with using the range is that it is entirely defined by the most extreme values in the sample and does not give any information about the rest of it. An alternative to this would be to give the range of the middle 50%, also known as the interquartile range (IQR).\nThe IQR is the difference between the 75th percentile, or upper quartile, and the 25th percentile, or lower quartile. As with the median, this is calculated by ordering the sample from smallest to largest. The sample is then cut into 4 and the quartiles are calculated. In R, the IQR is given as the difference between the upper and lower quartiles. To calculate these values separately, we can use the quantile function.\nBoth the range and IQR only use 2 values from the sample. As with the median, these measures discard a lot of information from the summaries. Where the sample is normally distributed, the standard deviation (SD) can be used which measures the average distance between each observation and the mean. The larger the SD, the wider and flatter the normal curve will be; the smaller the SD, the narrower and taller the curve will be:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe standard deviation is only appropriate where a numeric variable has a normal distribution, otherwise this value is meaningless.\n\n\nProperties of the normal distribution\nIf a sample is normally distributed, then it can be completely described using the mean and standard deviation, even when the sample values are not given. As the distribution is symmetrical, the mean and standard deviation can be used to estimate ranges of values.\nFor example, it is known that approximately 68% of a sample will lie one standard deviation from the mean, approximately 95% within 2 standard deviations from the mean, and around 99.7% within 3 standard deviations:\n\n\n\n\n\n\n\n\n\nThis knowledge can also be used to check the mean and standard deviation were appropriate summary statistics, even if we have no other information.",
    "crumbs": [
      "Tidyverse and data wrangling",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Combining and summarising datasets</span>"
    ]
  },
  {
    "objectID": "combining_summarising.html#exercise-4",
    "href": "combining_summarising.html#exercise-4",
    "title": "5  Combining and summarising datasets",
    "section": "Exercise 4",
    "text": "Exercise 4\n\nHow many respondents had both weekly rent and mortgage payments given? What are the potential reasons for this?\nCombine the weekly rent and mortgage variables into a single weekly payment variable.\n\n\n\n\n\n\n\nHint\n\n\n\nUse all available resources, including help files and cheatsheets if you are struggling to find a function to do this.\n\n\n\nCreate a summary table containing the mean, median, standard deviation, and the upper and lower quartiles of the weekly payment (rent and mortgage combined) for each region. What, if anything, can you infer about the distribution of this variable based on the table?",
    "crumbs": [
      "Tidyverse and data wrangling",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Combining and summarising datasets</span>"
    ]
  },
  {
    "objectID": "excel_data.html",
    "href": "excel_data.html",
    "title": "6  Loading and tidying Excel data",
    "section": "",
    "text": "6.1 Loading an Excel sheet into R\nAs with any file format, we must ensure data are in the correct form before loading them into R, ensuring each column represents a variable, each row represents an observation, and there are no tables or graphics.\nExcel files can be a little tricker to manipulate than SPSS and CSV files as they often contain multiple sheets. This is the case for the data that we will be using for this part of the course.\nThe Excel file that we will be loading contains the Office for Budget Responsibility (OBR) economic and fiscal outlook. This contains many sheets of data, but for this course we will just be focusing on three:\nLet’s begin with housing market data, stored in the 18th sheet, labelled “1.17”. This sheet can be selected in the read_xlsx function using the sheet argument.\nThe housing market sheet shows information over different time scales: first by quarters, then years, and then across pairs of years. For this example, we will extract information measured quarterly (rows 4 - 88). The argument range allows us to define the range of cells (by columns and rows) to extract.\nFinally, we can see that the column headers are not in an appropriate format for R: they contain spaces, brackets, and are very long! There are two approaches we will consider to overcome this.\nThe first is to remove the column names completely (by not including them in the range argument and setting col_names = FALSE within the read_xlsx function) and add them manually, using the setNames function.\nSetting names manually can take a long time and a lot of typing if there are many variables. An alternative to this manual approach is to include them in the range of the read_xlsx function, and use an R function to ‘clean’ them, making them follow the style guide.\nThe following code loads the housing market sheet and manually sets the variable names:\n# Return file names from the data folder\nlist.files(path = \"data\")\n\n[1] \"Detailed_forecast_tables_Economy_March_2024.xlsx\"\n[2] \"generalfs21_EUL.sav\"                             \n[3] \"interviewfs21_EUL.sav\"                           \n\nhousing_market &lt;- \n  read_xlsx(\"data/Detailed_forecast_tables_Economy_March_2024.xlsx\",\n                            # Specify the sheet and range of cells to keep\n                            sheet = \"1.17\",range = \"B4:J88\", \n                            # Remove column names (too messy)\n                            col_names = FALSE) %&gt;% \n  # Add variable names manually\n  setNames(c(\"period\", \"hpi_comp15\", \"hpi_prev_year\", \n             \"residential_property_transactions\", \n             \"private_enterprise_housing_starts\",\n             \"private_enterprise_housing_comp\", \n             \"housing_stock\", \"net_additions_housing_stock\",\n             \"turnover_rate\"))\nThe following code loads the same data but uses the janitor package.\nhousing_market_alt &lt;-\n  read_xlsx(\"data/Detailed_forecast_tables_Economy_March_2024.xlsx\",\n                                # Specify the sheet and range of cells to keep\n                                sheet = \"1.17\",range = \"B3:J88\") %&gt;% \n  # Removes spaces, special characters, all lower case, etc.\n  clean_names()",
    "crumbs": [
      "Tidyverse and data wrangling",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Loading and tidying Excel data</span>"
    ]
  },
  {
    "objectID": "excel_data.html#loading-an-excel-sheet-into-r",
    "href": "excel_data.html#loading-an-excel-sheet-into-r",
    "title": "6  Loading and tidying Excel data",
    "section": "",
    "text": "1.6 Labour market\n1.14 National living wage\n1.17 Housing market\n\n\n\n\n\n\n\n\n\n\n\n\nStyle tip\n\n\n\nThe janitor package has been designed to format inputed data to ensure it follows the Tidyverse style guide. The clean_names function can be applied to a data frame or tibble to adapt variable names in this way.\n\n\n\n\n\n\n\n\n\n\n\nWarning\n\n\n\nDo not run this code without installing and loading the janitor package first. We will not run this during the course, but it is included for future reference.",
    "crumbs": [
      "Tidyverse and data wrangling",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Loading and tidying Excel data</span>"
    ]
  },
  {
    "objectID": "excel_data.html#splitting-variables",
    "href": "excel_data.html#splitting-variables",
    "title": "6  Loading and tidying Excel data",
    "section": "6.2 Splitting variables",
    "text": "6.2 Splitting variables\nIn the current dataset, the time variable is given as a character and so is not recognised as ordered or temporal by R. To overcome this, we can split the variable to create separate year and quarter variables.\nThe str_sub function from tidyverse’s stringr package extracts elements based on their position in a string of characters. This can be used to return the first 4 digits to a new year variable, and the final digit to a new quarter variable:\n\nhousing_market &lt;- housing_market %&gt;%\n  # Don't forget to convert the string to numberic\n  mutate(year =  as.numeric(str_sub(period, start = 1, end = 4)),\n         quarter = as.numeric(str_sub(period, \n                              # Use - to work from the end of the string\n                              start = -1L, end = -1L))) %&gt;% \n  # Remove the original period variable\n  select(-period)",
    "crumbs": [
      "Tidyverse and data wrangling",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Loading and tidying Excel data</span>"
    ]
  },
  {
    "objectID": "excel_data.html#exercise-5",
    "href": "excel_data.html#exercise-5",
    "title": "6  Loading and tidying Excel data",
    "section": "Exercise 5",
    "text": "Exercise 5\n\nLoad in the OBR’s quarterly labour market data (sheet 1.6), keeping the following variables:\n\n\nPeriod\nEmployment rate (%)\nAverage earning growth (%)\nAverage earning index\nProductivity per hour index\nReal wage product\nReal consumption wage\n\nSplit the period data into separate year and quarter variables, ensure that all variable names follow Tidyverse’s style guide. Name this object labour_market.\n\nLoad the OBR’s national living wage data (sheet 1.14), keep as an object named living_wage.\n\n\n\n\n\n\n\nHint\n\n\n\nThe function paste0 is a base R function that combines arguments separated by commas into a single string without spaces. For example,\n\npaste0(\"abc\", 1, 10, \"_2010\")\n\n[1] \"abc110_2010\"",
    "crumbs": [
      "Tidyverse and data wrangling",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Loading and tidying Excel data</span>"
    ]
  },
  {
    "objectID": "excel_data.html#transforming-data",
    "href": "excel_data.html#transforming-data",
    "title": "6  Loading and tidying Excel data",
    "section": "6.3 Transforming data",
    "text": "6.3 Transforming data\nThe labour market and housing market data are currently considered in what is known as long format, with many rows and fewer variables. The alternative to this format, wide format, can be seen in the living wage data, which has many variables and very few (only one!) row. Sometimes we may wish to convert between these variables, either to join them to other datasets (as is the case here), or to carry out an analysis or visualisation that requires a certain format. These conversions are carried out using the pivot_longer or pivot_wider functions.\nThere are many ways to pivot data within R (see the helpfile ?pivot_longer for a full list of arguments), and the setup of this function tends to differ for every situation. For worked examples and a more detailed explanation of the function’s capabilities, enter vignette(\"pivot\") into the console.\nFor our data, we will need to convert the wide-format living wage data to a long-format so we are able to join it to the other data. This will create a new dataset with 2 variables: year and living_wage, with a row per year. The year variable will be taken from the wide data names, and the living_wage variable will come from the wide data values:\n\nliving_wage_long &lt;- living_wage %&gt;% \n  # First, select the columns that we wish to pivot (all of them)\n  pivot_longer(cols = everything(),\n               # Move the old variable names to a new year variable\n               names_to = \"year\",\n               # Remove the prefix from the old variable names\n               names_prefix = \"year_\",\n               # Convert the new year variable to numeric\n               names_transform = as.numeric,\n               # Take the old values and create a new living_wage variable\n               values_to = \"living_wage\")",
    "crumbs": [
      "Tidyverse and data wrangling",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Loading and tidying Excel data</span>"
    ]
  },
  {
    "objectID": "excel_data.html#exercise-6",
    "href": "excel_data.html#exercise-6",
    "title": "6  Loading and tidying Excel data",
    "section": "Exercise 6",
    "text": "Exercise 6\n\nCombine all three OBR datasets (housing market, labour market and living wage) together to create one complete dataset, obr_data.",
    "crumbs": [
      "Tidyverse and data wrangling",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Loading and tidying Excel data</span>"
    ]
  },
  {
    "objectID": "visualisation.html",
    "href": "visualisation.html",
    "title": "7  Data visualisation",
    "section": "",
    "text": "7.1 Choosing the most appropriate visualisation\nThe most appropriate choice of visualisation depends first and foremost on the goal, the context, and the audience of the visualisation. This choice will also be influenced (or restricted) by the type of variable(s) we wish to display and the number of variables. Common plots used to display combinations of different types of data are given in following table:\nNumber of variablesType of variablesVisualisationgeom object (or R function)One variableCategoricalFrequency tabletableBar chartgeom_barNumericalHistogramgeom_histogramSpatialMapgeom_sfTemporalLine plotgeom_lineTwo variablesTwo categoricalFrequency tabletableStacked/side-by-side bar chartgeom_barOne numeric, one categoricalDot plotgeom_pointBox plotgeom_boxplotTwo numericalScatterplotgeom_point&gt; 2 variables&gt; 2 categoricalTabletable2 numeric, one categorical or &gt; 2 numericScatterplot with different colours/symbols/sizesgeom_point\nFor a more comprehensive list (including some non-standard graphs), visit the From data to viz website.\nR is very flexible when it comes to visualising data and contains a wide variety of options to customise graphs. This section will focus on the tidyverse package ggplot2 and introduce some of the more commonly used graphical functions and parameters.",
    "crumbs": [
      "Data visualisation",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Data visualisation</span>"
    ]
  },
  {
    "objectID": "visualisation.html#the-ggplot2-package",
    "href": "visualisation.html#the-ggplot2-package",
    "title": "7  Data visualisation",
    "section": "7.2 The ggplot2 package",
    "text": "7.2 The ggplot2 package\nThe ggplot2 package implements the ‘grammar of graphics’, a system that aims to describe all statistical graphics in terms of their components or layers. All graphics can be broken down into the same components: the data, a coordinate system (or plot area) and some visual markings of the data. More complex plots may have additional layers but all must contain these three.\nFor example, if we want to investigate the distribution of tenure types between responses of the English Housing Survey (EHS), we could use a bar chart. The visual markings for a bar chart is a bar per group (in this case, tenure type), where the length of each bar represents the number of observations within that group.\nFor any visualisation created using ggplot2, we first use the ggplot function to create a coordinate system (a blank plot space) that we can add layers and objects to. Within this function, we specify the data that we wish to display on the coordinate system:\n\nggplot(data = ehs_tidy)\n\nTo add information to this graph, we add a geom layer: a visual representation of the data. There are many different geom objects built into the ggplot2 package (begin typing ?geom into the console to see a list). The geom_bar function is used to create bar charts.\nEach geom object must contain a mapping argument, coupled with the aes function which defines how the variables in the dataset are visualised. In this case, we use the aes function to specify the grouping variable on the x axis, but it can also be used to set the colour, size or symbol based on variable values.\n\n\n\n\n\n\nWarning\n\n\n\nAlthough ggplot2 is part of the tidverse package, it uses a + symbol to add layers to visualisations rather than the pipe %&gt;% we have been using in other packages.\n\n\n\nggplot(data = ehs_tidy) +\n  geom_bar(mapping = aes(x = tenure_type))\n\n\n\n\n\n\n\n\nGraphs appear in the plot tab in the bottom-right of the RStudio interface and can be opened in a new window using the  icon. Graphs in this window can also be copied and pasted into other documents using the  icon and selecting Copy to clipboard.\nNew graphs will replace existing ones in this window but all graphs created in the current session of R can be explored using the  icons.\nGraphs can be stored as objects using the &lt;- symbol. These objects can then be saved as picture or PDF files using the ggsave function:\n\ntenure_bar &lt;- ggplot(data = ehs_tidy) +\n  geom_line(aes(x = tenure_type))\n\nggsave(tenure_bar, filename = \"tenure_bar.png\")",
    "crumbs": [
      "Data visualisation",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Data visualisation</span>"
    ]
  },
  {
    "objectID": "visualisation.html#exercise-7",
    "href": "visualisation.html#exercise-7",
    "title": "7  Data visualisation",
    "section": "Exercise 7",
    "text": "Exercise 7\n\nChoose an appropriate visualisation to check the distribution of the gross income variable from respondents of the English Housing survey. Comment on your findings.\nBased on the output from question 1, generate a summary table giving the minimum, maximum gross income, and an appropriate measure of the centre and spread of this variable.",
    "crumbs": [
      "Data visualisation",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Data visualisation</span>"
    ]
  },
  {
    "objectID": "visualisation.html#customising-visualisations",
    "href": "visualisation.html#customising-visualisations",
    "title": "7  Data visualisation",
    "section": "7.3 Customising visualisations",
    "text": "7.3 Customising visualisations\nVisual markings of a ggplot object can be customised as part of the geom function. Arguments that can be adjusted within these geoms include:\n\ncolour: change the colour (if point or line) or outline (if bar or histogram) of the geom\nsize: change the size of the markings (if point used)\nshape: change the shape of markings (for points)\nfill: change the colour of bars in bar charts or histograms\nlinewidth: change the line width\nlinetype: choose the type of line (e.g. dotted)\nalpha: change the transparency of a geom\n\nThese options can be set manually or used to add variables to a visualisation. For example, the distribution of tenure types could be compared between regions by changing the fill of these bars, converting the bar chart into a stacked bar chart. When these options are determined by a variable in the data, they should be added inside the aes wrapper. Options can also be adjusted manually when the arguments are added outside of the aes wrapper.\nTo convert the previous bar chart into a stacked bar chart, we define fill by the region variable. To make these distinctions easier to see, we can also add a black outline to the bars by manually setting colour:\n\nggplot(data = ehs_tidy) + \n  # Define the x axis and fill inside aes\n  geom_bar(aes(x = tenure_type, fill = region),\n           # Manually define colour outside aes\n           colour = \"black\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nStyle tip\n\n\n\nR contains a list of 657 pre-programmed colours that can be used to create palettes (run colours() in the console for a full list). Hexadecimal codes can also be included instead in the form #rrggbb (where rr (red), gg (green), and bb (blue) are numbers between 00 and 99 giving the level of intensity of each colour).\n\n\nEach geom has different arguments that can be customised to adapt visualisations. For example, geom_bar has the position argument which controls how additional groups are displayed. By default, this argument is set to \"stack\" which created a stacked bar chart as we saw in the last example. An alternative would be to set this to position = \"dodge\" which creates a side-by-side bar chart. Here, the tenure type bars are separated into smaller bars per region, but are displayed next to one another, rather than on top of each other:\n\nggplot(data = ehs_tidy) + \n  # Define the x axis and fill inside aes\n  geom_bar(aes(x = tenure_type, fill = region),\n           # Manually define colour outside aes\n           colour = \"black\",\n           # Show bars side-by-side instead of stacked\n           position = \"dodge\")\n\n\n\n\n\n\n\n\nFor a more comprehensive list of the options available for the geom you are interested in, check the helpfile (e.g. ?geom_bar).\n\n\n\n\n\n\nWarning\n\n\n\nAlthough it may be tempting to add many variables to the same visualisation, be sure that you are not overcomplicating the graph and losing important messages. It is better to have multiple clear (but simpler) visualisations than fewer confusing ones.\n\n\n\nA note on colour in visualisations\nThe use of colour in visualisations can help highlight important messages, add variables to a graph, or make the visualisation stand out. However, unnecessary colours can distract from important data and make a message less clear.\nWhere colours are useful in a visualisation, ensure the choice of palette is inclusive and accessible. This means ensuring that colours are distinct to everyone, including those with a colour-vision deficiency, and avoid potentially harmful stereotypes.\nTo check a colour palette is inclusive, consider using a colour blindness simulator such as this one.",
    "crumbs": [
      "Data visualisation",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Data visualisation</span>"
    ]
  },
  {
    "objectID": "visualisation.html#exercise-8",
    "href": "visualisation.html#exercise-8",
    "title": "7  Data visualisation",
    "section": "Exercise 8",
    "text": "Exercise 8\nChoose an appropriate visualisation to investigate the change in employment rate between 2008 and 2024. Generate this visualisation and comment on your findings.",
    "crumbs": [
      "Data visualisation",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Data visualisation</span>"
    ]
  },
  {
    "objectID": "visualisation.html#scale-functions",
    "href": "visualisation.html#scale-functions",
    "title": "7  Data visualisation",
    "section": "7.4 Scale functions",
    "text": "7.4 Scale functions\nScale functions allow us to customise aesthetics defined in geom objects, such as colours and axes labels. They take the form scale_'aesthetic to customise'_'scale of variable’.\n\n7.4.1 Customising axes\nScale functions can be used to customise axis titles, limits, breaks, and labels. The choice of scale function is determined by the type of variable displayed on the axis.\nFor example, if we wanted to customise the x axis of the line graph generated in the previous exercise, showing the employment rate over time, we would use the scale_x_continuous function. Arguments to customise the x or y axes include:\n\nname = to change the axis title\nlimits = c(...) sets the axis limits\nbreaks = c(...) defines tick marks\nlabels = c(...) attaches labels to break values\ntransform = transforms the scale that the axis is shown on (for some older versions of ggplot2, this option is trans but has been overwritten in newer versions).\n\nIn this example, we can add labels to the x axis that shows which year the time variable represents, making it easier to interpret:\n\nggplot(data = obr_data) +\n  geom_line(aes(x = time, y = employment_rate)) +\n  # Add axis title\n  scale_x_continuous(name = \"Year\", \n                     # Add breaks for each year\n                     breaks = seq(1, 65, by = 4),\n                     # Add labels to breaks\n                     labels = 2008:2024)\n\n\n\n\n\n\n\n\n\n\n7.4.2 Customising colour scales\nThere are a wide range of options for customising the colour aesthetics of geoms. These include pre-defined colour palettes, such as scale_colour_viridis_c for continuous variables, or scale_colour_viridis_d for discrete or categorical variables. Viridis colour palettes are designed to be colourblind friendly and print well in grey scale. There are also many R packages containing colour palettes for different scenarios. This website gives a list and preview of all palettes currently available.\nColour palettes can also be created manually for categorical variables using the scale_colour_manual function. Here, the argument values allows us to specify a colour per category.\nWhere a colour palette will be used across multiple plots, defining this list of colours as a vector and then entering this into scale_fill_manual will reduce repetitive coding. For example, where region is used to group across multiple plots, it will be useful to create a region colour palette:\n\nregion_palette &lt;- c(\"aquamarine2\", \"blue\", \"chartreuse2\", \"coral\", \"orchid\",\n                    \"firebrick\", \"gold3\", \"violetred\", \"grey50\")\n\nggplot(data = ehs_tidy) + \n  # Define the x axis and fill inside aes\n  geom_bar(aes(x = tenure_type, fill = region),\n           # Manually define colour outside aes\n           colour = \"black\",\n           # Show bars side-by-side instead of stacked\n           position = \"dodge\") +\n  # Change legend title and add colour values\n  scale_fill_manual(name = \"Region\", values = region_palette)\n\n\n\n\n\n\n\n\nPalettes can also be created using gradients with the scale_colour_gradient function, that specifies a two colour gradient from low to high, scale_colour_gradient2 that creates a diverging gradient using low, medium, and high colours, and scale_colour_gradientn that creates an n-colour gradient.",
    "crumbs": [
      "Data visualisation",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Data visualisation</span>"
    ]
  },
  {
    "objectID": "visualisation.html#other-labelling-functions",
    "href": "visualisation.html#other-labelling-functions",
    "title": "7  Data visualisation",
    "section": "7.5 Other labelling functions",
    "text": "7.5 Other labelling functions\nAlthough axis and legend labels can be updated within scale functions, the labs function exist as an alternative. This function also allows us to add titles and subtitles to visualisations:\n\nlabs(x = “x-axis name”, y = “y-axis name”,\n    colour = “Grouping variable name”, title = “Main title”,\n    subtitle = “Subtitle”, caption = “Footnote”)\n\nThe annotate function allows us to add text and other objects to a ggplot object. For example:\n\nannotate(“text”, x = 50, y = 200, label = “Text label here”)\n\nAdds “Text label here” to a plot at the coordinates (50, 200) on a graph, and\n\nannotate(“rect”, xmin = 0, xmax = 10, ymin = 20, ymax = 50, alpha = 0.2)\n\nadds a rectangle to the graph.\n\n\n\n\n\n\nStyle tip\n\n\n\nMake use of annotations in visualisations to enhance important messages and draw readers’ attention.",
    "crumbs": [
      "Data visualisation",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Data visualisation</span>"
    ]
  },
  {
    "objectID": "visualisation.html#theme-functions",
    "href": "visualisation.html#theme-functions",
    "title": "7  Data visualisation",
    "section": "7.6 Theme functions",
    "text": "7.6 Theme functions\nThe theme function modifies non-data components of the visualisation. For example, the legend position, label fonts, the graph background, and gridlines. There are many options that exist within the theme function (use ?theme to list them all).\n\n\n\n\n\n\nNote\n\n\n\nMany of the elements that can be customised within the theme function require an element wrapper. This wrapper is determined by the type of object we are customising (e.g. element_text when customising text, element_rect when customising a background, element_blank to remove something). Check ?theme for more information.\n\n\nOne of the most common theme options is legend.position which can be used to move the legend to the top or bottom of the graph space (legend.position = “top” or legend.position = “bottom”) or remove the legend completely (legend.position = “none”).\nggplot also contains a number of pre-defined themes which change non-data elements of the plot to a programmed default. For example theme_void removes all gridlines and axes, theme_light changes the graph background white and the gridlines and axes light grey:\n\nggplot(data = ehs_tidy) + \n  # Define the x axis and fill inside aes\n  geom_bar(aes(x = tenure_type, fill = region),\n           # Manually define colour outside aes\n           colour = \"black\",\n           # Show bars side-by-side instead of stacked\n           position = \"dodge\") +\n  # Change legend title and add colour values\n  scale_fill_manual(name = \"Region\", values = region_palette) + \n  # Remove gridlines and axes (not recommended!!)\n  theme_void()\n\n\n\n\n\n\n\n\nOne benefit of using themes is that all visualisations will be consistent in terms of colour scheme, font size and gridlines. Although there are pre-built themes, we are able to create our own and save them as functions. These can then be used in place of R’s themes.\n\n7.6.1 Creating functions\nTo create our own function in R, we first give it a name and attach function() followed by curly brackets {}, with the function defined inside those brackets.\nFor example, to create our own theme function, called theme_dluch, which sets the title font size to 18, the axis and legend titles to size 15, the axis and legend text to size 12, adds just gridlines to the y-axis, and changes the background colours, we use the following:\n\ntheme_dluch &lt;- function() {\n  # Change plot title size\n  theme(plot.title = element_text(size = 18),\n        # Change axis title size\n        axis.title = element_text(size = 15),\n        # Change axis text size\n        axis.text = element_text(size = 12),\n        # Change legend text\n        legend.text = element_text(size = 12),\n        legend.title = element_text(size = 15),\n        # Change background\n        plot.background = element_rect(fill = \"thistle\"),\n        # Change legend background to match\n        legend.background = element_rect(fill = \"thistle\"),\n        # Change graph area background\n        panel.background = element_rect(fill = \"white\", \n                                        colour = \"black\"),\n        # Add tick major tick marks for the y axis (but not x)\n        panel.grid.major.y = element_line(colour = \"grey55\"))\n}\n\nThe function theme_dluch will now appear in the Environment window and can be added to ggplot objects:\n\nggplot(data = ehs_tidy) + \n  # Define the x axis and fill inside aes\n  geom_bar(aes(x = tenure_type, fill = region),\n           # Manually define colour outside aes\n           colour = \"black\",\n           # Show bars side-by-side instead of stacked\n           position = \"dodge\") +\n  # Change legend title and add colour values\n  scale_fill_manual(name = \"Region\", values = region_palette) +\n  # The change of font has made the labels unreadable, wrap them \n  # onto a new line when too long\n  scale_x_discrete(labels = label_wrap_gen(12)) +\n  labs(x = \"Tenure type\", y = \"Count\") +\n  # Remove gridlines and axes (not recommended!!)\n  theme_dluch()\n\n\n\n\n\n\n\n\nCreating a personalised theme ensures that visualisations are consistent, whilst keeping code concise and reducing repetition.\n\n\nA note on visualisation styling and accessibility\nIn all data visualisations, we want to make sure that the data are the most important element. We should aim to reduce all unnecessary clutter and design choices that do not enhance or add context to the data. This includes unnecessary patterns, colours, and gridlines.\nText must be legible to all readers, including those with visual impairments or learning difficulties. All text should be at least 12pt when the visualisation will be printed (e.g. in reports), or 36pt when included in a presentation. Do not choose a font family that is inaccessible.",
    "crumbs": [
      "Data visualisation",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Data visualisation</span>"
    ]
  },
  {
    "objectID": "visualisation.html#facet-functions",
    "href": "visualisation.html#facet-functions",
    "title": "7  Data visualisation",
    "section": "7.7 Facet functions",
    "text": "7.7 Facet functions\nFaceting allows us to divide a plot into subplots based on some grouping variable within the data. This allows us to show multiple variables in the same visualisation without risking overloading the plot and losing the intended message.\nFor example, we could compare the relationship between gross income and tenure type (shown using a boxplot) between regions by faceting the graph by region using the facet_wrap function:\n\n\n\n\n\n\nWarning\n\n\n\nRemember that the value 100,000 actually represents anyone earning £100,000 or more. To avoid skewing the data, we will remove these values and investigate trends below this threshold.\n\n\n\nehs_tidy %&gt;% \n  # Remove gross income &gt;= £100,000\n  filter(gross_income != 100000) %&gt;% \n  # Do not need to specify data, it is already passed through the pipes\n  ggplot() +\n  geom_boxplot(aes(x = tenure_type, y = gross_income)) +\n  scale_x_discrete(labels = label_wrap_gen(12)) +\n  labs(x = \"Tenure type\", y = \"Gross income (£)\") +\n  facet_wrap( ~ region)",
    "crumbs": [
      "Data visualisation",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Data visualisation</span>"
    ]
  },
  {
    "objectID": "visualisation.html#exercise-9",
    "href": "visualisation.html#exercise-9",
    "title": "7  Data visualisation",
    "section": "Exercise 9",
    "text": "Exercise 9\nUse an appropriate visualisation to investigate the relationship between house prices and wages between 2008 and now. Ensure that the variables you choose are comparable and treat this as though the final product will be exported into a report (make sure it is clear and looks good!). Interpret your final graph.",
    "crumbs": [
      "Data visualisation",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Data visualisation</span>"
    ]
  },
  {
    "objectID": "exercise3_solutions.html",
    "href": "exercise3_solutions.html",
    "title": "Appendix A — Exercise 3 solutions",
    "section": "",
    "text": "A.1 Question 1\nYou have been provided with another .sav file which contains the interview responses from the EHS. Create and save a tidy version of this dataset, ensuring variables are classified as the correct type and names follow the style conventions (if you cannot remember these, check here for a reminder.\nThe variables we need in the tidy dataset are:",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Exercise 3 solutions</span>"
    ]
  },
  {
    "objectID": "exercise3_solutions.html#question-1",
    "href": "exercise3_solutions.html#question-1",
    "title": "Appendix A — Exercise 3 solutions",
    "section": "",
    "text": "The unique identifier serialanon\nThe gross household income HYEARGRx\nThe length of residence lenresb\nThe weekly rent rentwkx and mortgage mortwkx payments\nWhether the property is freehold or leasehold freeLeas\n\n\nSolution\nThe first step is to load in the data. However, before this, we need the name of the file. We can look into our documents to get this, but the list.files function will do it for us:\n\nlist.files(path = \"data\")\n\n[1] \"Detailed_forecast_tables_Economy_March_2024.xlsx\"\n[2] \"generalfs21_EUL.sav\"                             \n[3] \"interviewfs21_EUL.sav\"                           \n\n\nFrom the console, we can copy and paste the file name into the read_spss function:\n\nehs_interview_tidy &lt;- read_spss(\"data/interviewfs21_EUL.sav\")\n\nNext, we can select just the variables we need to reduce the data size:\n\nehs_interview_tidy &lt;- read_spss(\"data/interviewfs21_EUL.sav\") %&gt;% \n  select(serialanon, HYEARGRx, lenresb, rentwkx, mortwkx, freeLeas)\n\nWe can now explore this data to see which variables need converting, and which are truly numeric:\n\nstr(ehs_interview_tidy)\n\ntibble [9,752 × 6] (S3: tbl_df/tbl/data.frame)\n $ serialanon: dbl+lbl [1:9752] 2.02e+10, 2.02e+10, 2.02e+10, 2.02e+10, 2.02e+10, 2.0...\n   ..@ label        : chr \"Key variable: unique archived identifier\"\n   ..@ format.spss  : chr \"F11.0\"\n   ..@ display_width: int 13\n   ..@ labels       : Named num [1:2] -9 -8\n   .. ..- attr(*, \"names\")= chr [1:2] \"Does not apply\" \"No Answer\"\n $ HYEARGRx  : dbl+lbl [1:9752]  38378,  26525,  25273,  51280,  14365,  38955,  2137...\n   ..@ label        : chr \"Household gross annual income (inc. income from all adult household members)\"\n   ..@ format.spss  : chr \"F8.2\"\n   ..@ display_width: int 10\n   ..@ labels       : Named num 1e+05\n   .. ..- attr(*, \"names\")= chr \"£100,000 or more\"\n $ lenresb   : dbl+lbl [1:9752] 7, 8, 6, 4, 8, 8, 6, 2, 6, 8, 6, 4, 8, 5, 4, 5, 4, 3,...\n   ..@ label        : chr \"Length of residence\"\n   ..@ format.spss  : chr \"F8.0\"\n   ..@ display_width: int 10\n   ..@ labels       : Named num [1:10] -9 -8 1 2 3 4 5 6 7 8\n   .. ..- attr(*, \"names\")= chr [1:10] \"does not apply\" \"no answer\" \"less than 1 year\" \"one year\" ...\n $ rentwkx   : dbl+lbl [1:9752]    NA,    NA,    NA,    NA,    NA,    NA,    NA,    N...\n   ..@ label        : chr \"Total weekly rent payable (rent plus housing benefit)\"\n   ..@ format.spss  : chr \"F8.2\"\n   ..@ display_width: int 10\n   ..@ labels       : Named num -9\n   .. ..- attr(*, \"names\")= chr \"question not applicable - owner occupier and not shared ownership\"\n $ mortwkx   : dbl+lbl [1:9752]    NA,    NA,    NA, 184.6,  88.8,    NA,    NA, 313....\n   ..@ label        : chr \"Weekly mortgage payments\"\n   ..@ format.spss  : chr \"F8.2\"\n   ..@ display_width: int 10\n   ..@ labels       : Named num [1:3] -9 -8 0\n   .. ..- attr(*, \"names\")= chr [1:3] \"not applicable - tenant\" \"unknown\" \"no payments - own outright\"\n $ freeLeas  : dbl+lbl [1:9752]  1,  1,  1,  1,  1,  1,  1,  1, NA,  1,  1, NA,  1, N...\n   ..@ label        : chr \"Freehold or leasehold\"\n   ..@ format.spss  : chr \"F8.0\"\n   ..@ display_width: int 10\n   ..@ labels       : Named num [1:4] -9 -8 1 2\n   .. ..- attr(*, \"names\")= chr [1:4] \"does not apply\" \"no answer\" \"freehold\" \"leasehold\"\n - attr(*, \"label\")= chr \"Aggregated File\"\n\n\nAs with the general data, all variables are classified as dbl + lbl by R. Of these, the length of residence and freehold/leashold variables appear to by categorical. There are also labels attached to the gross annual income (for those over £100,000) which we need to be aware of when analysing this data.\nTherefore, our next step will involve converting the categorical variables into factors:\n\nehs_interview_tidy &lt;- read_spss(\"data/interviewfs21_EUL.sav\") %&gt;% \n  select(serialanon, HYEARGRx, lenresb, rentwkx, mortwkx, freeLeas) %&gt;% \n  mutate(length_residence = as_factor(lenresb),\n         freehold_leasehold = as_factor(freeLeas))\n\nhead(ehs_interview_tidy)\n\n# A tibble: 6 × 8\n  serialanon  HYEARGRx  lenresb        rentwkx mortwkx freeLeas length_residence\n  &lt;dbl+lbl&gt;   &lt;dbl+lbl&gt; &lt;dbl+lbl&gt;      &lt;dbl+l&gt; &lt;dbl+l&gt; &lt;dbl+lb&gt; &lt;fct&gt;           \n1 20220000001 38378.    7 [20-29 year… NA       NA     1 [free… 20-29 years     \n2 20220000005 26525     8 [30+ years]  NA       NA     1 [free… 30+ years       \n3 20220000006 25272.    6 [10-19 year… NA       NA     1 [free… 10-19 years     \n4 20220000012 51280.    4 [3-4 years]  NA      185.    1 [free… 3-4 years       \n5 20220000013 14365     8 [30+ years]  NA       88.8   1 [free… 30+ years       \n6 20220000017 38955     8 [30+ years]  NA       NA     1 [free… 30+ years       \n# ℹ 1 more variable: freehold_leasehold &lt;fct&gt;\n\n\nFinally, we need to rename the existing variables to ensure they are informative and follow the style rules, and remove any unnecessary variables:\n\nehs_interview_tidy &lt;- read_spss(\"data/interviewfs21_EUL.sav\") %&gt;% \n  select(serialanon, HYEARGRx, lenresb, rentwkx, mortwkx, freeLeas) %&gt;% \n  mutate(length_residence = as_factor(lenresb),\n         freehold_leasehold = as_factor(freeLeas)) %&gt;% \n  rename(id = serialanon,\n         gross_income = HYEARGRx,\n         weekly_rent = rentwkx,\n         weekly_mortgage = mortwkx) %&gt;% \n  select(id, gross_income, length_residence, weekly_rent, weekly_mortgage, \n         freehold_leasehold)",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Exercise 3 solutions</span>"
    ]
  },
  {
    "objectID": "exercise3_solutions.html#question-2",
    "href": "exercise3_solutions.html#question-2",
    "title": "Appendix A — Exercise 3 solutions",
    "section": "A.2 Question 2",
    "text": "A.2 Question 2\nSave the tidy interview dataset as a csv file with an appropriate file name.\n\nSolution\n\nwrite_csv(ehs_interview_tidy, file = \"saved_data/ehs_interview_tidy.csv\")",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Exercise 3 solutions</span>"
    ]
  },
  {
    "objectID": "exercise3_solutions.html#question-3",
    "href": "exercise3_solutions.html#question-3",
    "title": "Appendix A — Exercise 3 solutions",
    "section": "A.3 Question 3",
    "text": "A.3 Question 3\nUsing the new, tidy dataset, answer the following questions:\n\nHow many respondents paid weekly rent of between £150 and £300?\nHow many respondents did not give a response to either the weekly rent or weekly mortgage question?\nWhat is the highest household gross income of these responders?\n\n\nSolution\nFor the first two part, we use the filter function to return a subgroup matching the condition, and combine this with the count function that counts the number of rows in a tibble:\n\nehs_interview_tidy %&gt;% \n  filter(between(weekly_rent, 150, 300)) %&gt;% \n  count()\n\n# A tibble: 1 × 1\n      n\n  &lt;int&gt;\n1   993\n\nehs_interview_tidy %&gt;% \n  filter(is.na(weekly_rent), is.na(weekly_mortgage)) %&gt;% \n  count()\n\n# A tibble: 1 × 1\n      n\n  &lt;int&gt;\n1  2956\n\n\nThere were 993 respondents that paid weekly rent of between £150 and £300.\nThere were 2956 respondents that did not give a response to either the weekly rent or mortgage question.\nThe final part could usually be carried out with the base R max function:\n\nmax(ehs_interview_tidy$gross_income)\n\n&lt;labelled&lt;double&gt;[1]&gt;: Household gross annual income (inc. income from all adult household members)\n[1] 1e+05\n\nLabels:\n value            label\n 1e+05 £100,000 or more\n\n\nHowever, the labels attached to the SPSS file showed that a value of 100000 actually represents a group of responders earning at least £100,000. Therefore, we cannot answer this question from the available data. If we were to analyse this variable, we would need to categorise the rest of the data, losing a lot of information. Failure to do this would produce invalid results.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Exercise 3 solutions</span>"
    ]
  },
  {
    "objectID": "exercise4_solutions.html",
    "href": "exercise4_solutions.html",
    "title": "Appendix B — Exercise 4 solutions",
    "section": "",
    "text": "B.1 Question 1\nHow many respondents had both weekly rent and mortgage payments given? What are the potential reasons for this?",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Exercise 4 solutions</span>"
    ]
  },
  {
    "objectID": "exercise4_solutions.html#question-1",
    "href": "exercise4_solutions.html#question-1",
    "title": "Appendix B — Exercise 4 solutions",
    "section": "",
    "text": "Solution\nWe can combine the filter and count functions to answer the first part of this question:\n\nehs_tidy %&gt;% \n  filter(!is.na(weekly_rent), !is.na(weekly_mortgage)) %&gt;% \n  count()\n\n# A tibble: 1 × 1\n      n\n  &lt;int&gt;\n1   105\n\n\nThere were 105 respondents with both weekly rent and mortgage payments.\nTo understand why this is, we could first view this data (or a summary of the data) to see what other characteristics these respondents share:\n\nehs_tidy %&gt;% \n  filter(!is.na(weekly_rent), !is.na(weekly_mortgage)) %&gt;% \n  summary()\n\n       id              weighting                    tenure_type \n Min.   :2.022e+10   Min.   :  305.5   housing association:  0  \n 1st Qu.:2.022e+10   1st Qu.:  628.9   local authority    :  0  \n Median :2.022e+10   Median : 1058.4   owner occupied     :105  \n Mean   :2.022e+10   Mean   : 1859.3   private rented     :  0  \n 3rd Qu.:2.022e+10   3rd Qu.: 2535.4                            \n Max.   :2.022e+10   Max.   :10568.5                            \n                                                                \n           region    gross_income            length_residence  weekly_rent    \n South East   :22   Min.   :  9880   two years       :27      Min.   :  8.30  \n East         :19   1st Qu.: 26595   one year        :19      1st Qu.: 49.80  \n London       :19   Median : 39655   3-4 years       :15      Median : 69.69  \n North West   :13   Mean   : 41908   5-9 years       :15      Mean   : 86.23  \n South West   :13   3rd Qu.: 52323   less than 1 year: 9      3rd Qu.:120.00  \n East Midlands: 8   Max.   :100000   10-19 years     : 8      Max.   :219.23  \n (Other)      :11                    (Other)         :12                      \n weekly_mortgage    freehold_leasehold\n Min.   :  0.0231   freehold :29      \n 1st Qu.:  0.0231   leasehold:65      \n Median : 60.0000   NA's     :11      \n Mean   : 71.6271                     \n 3rd Qu.:103.8462                     \n Max.   :343.8138                     \n                                      \n\n\nAll respondents in this group owned and lived in their own home. Most were leasehold properties, suggesting some of the weekly rent refers to lease payments. Other potential reasons could include shared ownership (which is not given as an option for tenure type), or respondents that lived with renters in the same property.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Exercise 4 solutions</span>"
    ]
  },
  {
    "objectID": "exercise4_solutions.html#question-2",
    "href": "exercise4_solutions.html#question-2",
    "title": "Appendix B — Exercise 4 solutions",
    "section": "B.2 Question 2",
    "text": "B.2 Question 2\nCombine the weekly rent and mortgage variables into a single weekly payment variable.\n\nSolution\nWhere only one value has been recorded, we want to use this in the new variable. Where both have been recorded, we will need to add the values together to get a weekly total.\nThere are a few different ways to do this. The first is to include an if_else statement in the mutate function, changing how the variable is calculated whether either value is missing or not:\n\nehs_tidy_ex4 &lt;- ehs_tidy %&gt;% \n  # if either weekly_rent or weekly_mortgage are missing\n  mutate(weekly_total = if_else(is.na(weekly_rent) | is.na(weekly_mortgage), \n                                # return the non-missing value\n                                coalesce(weekly_rent, weekly_mortgage), \n                                # if neither are missing, add the variables together\n                                weekly_rent + weekly_mortgage))\n\nAn alternative would be to use rowwise which groups data by rows and carries out operations across rows rather than columns. This can be combined with the sum function which contains the optional na.rm argument to remove missing values:\n\nehs_tidy_ex4 &lt;- ehs_tidy %&gt;% \n  # group data by rows\n  rowwise() %&gt;% \n  # add totals by using the sum function which has the argument na.rm to remove missing data\n  mutate(weekly_total = sum(weekly_rent, weekly_mortgage, na.rm = TRUE))\n\n\n\n\n\n\n\nWarning\n\n\n\nIn this case, we cannot use the rowwise option as it replaces missing values with zeros. Some of the households missing both rent and mortgage values may be a result of an incomplete survey rather than no payments. To avoid this, we will use if_else to create the newest variable.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Exercise 4 solutions</span>"
    ]
  },
  {
    "objectID": "exercise4_solutions.html#question-3",
    "href": "exercise4_solutions.html#question-3",
    "title": "Appendix B — Exercise 4 solutions",
    "section": "B.3 Question 3",
    "text": "B.3 Question 3\nCreate a summary table containing the mean, median, standard deviation, and the upper and lower quartiles of the weekly payment (rent and mortgage combined) for each region. What, if anything, can you infer about the distribution of this variable based on the table?\n\nSolution\n\nehs_tidy_ex4 %&gt;% \n  # Give summaries by region\n  group_by(region) %&gt;% \n  # List summaries required\n  summarise(mean_payment = mean(weekly_total, na.rm = TRUE),\n            median_payment = median(weekly_total, na.rm = TRUE),\n            sd_payment = sd(weekly_total, na.rm = TRUE),\n            lq_payment = quantile(weekly_total, .25, na.rm = TRUE),\n            uq_payment = quantile(weekly_total, .75, na.rm = TRUE)) %&gt;%\n  # Be sure to remove the grouping!\n  ungroup()\n\n# A tibble: 9 × 6\n  region            mean_payment median_payment sd_payment lq_payment uq_payment\n  &lt;fct&gt;                    &lt;dbl&gt;          &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;\n1 East                      172.          138.       135.       101.        208.\n2 East Midlands             144.          121.       100.        92.3       162.\n3 London                    268.          214.       226.       127.        346.\n4 North East                107.           92.3       52.0       80         115.\n5 North West                121.          104.        69.2       84         138.\n6 South East                202.          166.       153.       115         245.\n7 South West                148.          127         93.6       93.2       183.\n8 West Midlands             131.          106.       100.        86.3       150 \n9 Yorkshire and th…         118.           99.2      103.        79.8       133.\n\n\nThere are big differences between most mean and medians across regions, indicating that the data are not normally distributed. If we use the approximate 95% range formula (mean \\(\\pm\\) (2 \\(\\times\\) sd)), we would get negative values for all regions. Negative payments do not make sense in this context, confirming that the data are not normally distributed.\nIn this case, the median and IQR should be give, not the mean and standard deviation.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Exercise 4 solutions</span>"
    ]
  },
  {
    "objectID": "exercise5_solutions.html",
    "href": "exercise5_solutions.html",
    "title": "Appendix C — Exercise 5 solutions",
    "section": "",
    "text": "C.1 Question 1\nLoad in the OBR’s quarterly labour market data (sheet 1.6), keeping the following variables:\nSplit the period data into separate year and quarter variables. Ensure that all variable names follow Tidyverse’s style guide.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>Exercise 5 solutions</span>"
    ]
  },
  {
    "objectID": "exercise5_solutions.html#question-1",
    "href": "exercise5_solutions.html#question-1",
    "title": "Appendix C — Exercise 5 solutions",
    "section": "",
    "text": "Period\nEmployment rate (%)\nAverage earning growth (%)\nAverage earning index\nProductivity per hour index\nReal wage product\nReal consumption wage\n\n\n\nSolution\nUsing the same approach as the housing market sheet, load the range of cells containing the data required, not including the variable names. Add variable names manually after selecting the variables required, then split the time variable into years and quarters.\n\n# List files in data folder (to copy and paste file name!)\nlist.files(path = \"data\")\n\n[1] \"Detailed_forecast_tables_Economy_March_2024.xlsx\"\n[2] \"generalfs21_EUL.sav\"                             \n[3] \"interviewfs21_EUL.sav\"                           \n\nlabour_market &lt;- \n  read_xlsx(\"data/Detailed_forecast_tables_Economy_March_2024.xlsx\",\n            # Specify the sheet and range of cells to keep\n            sheet = \"1.6\",range = c(\"B4:V88\"), \n            # Remove column names (too messy)\n            col_names = FALSE) %&gt;% \n  # Select the variables needed by their position\n  select(1, 3, 15, 16, 18, 20, 21) %&gt;% \n  # Add variable names manually\n  setNames(c(\"period\", \"employment_rate\", \"earning_growth\", \"earning_index\", \n             \"productivity_hour\", \"real_product_wage\",\n             \"real_consumption_wage\")) %&gt;% \n  # Split the period variable into years and quarter\n  mutate(year = as.numeric(str_sub(period, start = 1L, end = 4L)),\n         quarter = as.numeric(str_sub(period, start = -1L, end = -1L))) %&gt;% \n  # Remove the perioud variable\n  select(-period)",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>Exercise 5 solutions</span>"
    ]
  },
  {
    "objectID": "exercise5_solutions.html#question-2",
    "href": "exercise5_solutions.html#question-2",
    "title": "Appendix C — Exercise 5 solutions",
    "section": "C.2 Question 2",
    "text": "C.2 Question 2\nLoad the OBR’s national living wage data (sheet 1.14).\n\nSolution\nUsing the same approach as earlier, load the correct sheet in, selecting cells with data included. Variable names cannot begin with numbers, so rename them either manually, or by adding a prefix. The rename_with function allows us to rename variables by applying a function to them, in this case paste0 which combines elements in the function separated by commas:\n\nliving_wage &lt;- \n  read_xlsx(\"data/Detailed_forecast_tables_Economy_March_2024.xlsx\",\n            # Specify the sheet and range of cells to keep\n            sheet = \"1.14\", range = c(\"C4:K5\")) %&gt;% \n  # Rename variables by pasting the prefix \"year_\" to the original name\n  rename_with(~paste0(\"year_\", .x))",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>Exercise 5 solutions</span>"
    ]
  },
  {
    "objectID": "exercise6_solutions.html",
    "href": "exercise6_solutions.html",
    "title": "Appendix D — Exercise 6 solutions",
    "section": "",
    "text": "D.1 Question\nCombine all three OBR datasets (housing market, labour market and living wage) together to create one complete dataset, obr_data.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>D</span>  <span class='chapter-title'>Exercise 6 solutions</span>"
    ]
  },
  {
    "objectID": "exercise6_solutions.html#question",
    "href": "exercise6_solutions.html#question",
    "title": "Appendix D — Exercise 6 solutions",
    "section": "",
    "text": "Solution\nUse full_join to combine the housing and labour market data by year and quarter, then pipe to apply full_join to the resulting data and add the living wage, joining by year. As there are multiple year rows in the housing and labour market data, include the argument muliple = \"all\" to ensure the living wage variable is repeated for each quarter.\n\n# full join the housing and labour market data\nobr_data &lt;- full_join(housing_market, labour_market, \n                      by = c(\"year\", \"quarter\")) %&gt;% \n  # join this data to the living wage\n  full_join(., living_wage_long, by = \"year\", multiple = \"all\")",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>D</span>  <span class='chapter-title'>Exercise 6 solutions</span>"
    ]
  },
  {
    "objectID": "exercise7_solutions.html",
    "href": "exercise7_solutions.html",
    "title": "Appendix E — Exercise 7 solutions",
    "section": "",
    "text": "E.1 Question 1\nChoose an appropriate visualisation to check the distribution of the gross income variable from respondents of the English Housing survey. Comment on your findings.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>E</span>  <span class='chapter-title'>Exercise 7 solutions</span>"
    ]
  },
  {
    "objectID": "exercise7_solutions.html#question-1",
    "href": "exercise7_solutions.html#question-1",
    "title": "Appendix E — Exercise 7 solutions",
    "section": "",
    "text": "Solution\nThe most appropriate visualisation to check the distribution of a numeric variable is a histogram. This can be created using the geom_histogram function within ggplot2:\n\nggplot(data = ehs_tidy) +\n  geom_histogram(aes(x = gross_income))\n\n\n\n\n\n\n\n\nThe histogram shows a strange peak at £100,000. This is because a value of 100000 in this data actually represents any household with a gross income of £100,000 or more. To avoid this distorting our visualisation and any future analysis, we will remove any observations with this value and save it as a new dataset:\n\nehs_tidy_new &lt;- filter(ehs_tidy,\n                       gross_income != 100000)\n\n\n\n\n\n\n\nWarning\n\n\n\nRemoving these observations means losing all of the information recorded on these respondents. We always want to keep the data in its fullest form where possible. Where we need a categorical versions of this variable, this can be included within the same dataset but always keep the raw data.\n\n\n\nggplot(data = ehs_tidy_new) +\n  geom_histogram(aes(x = gross_income))\n\n\n\n\n\n\n\n\nThe gross income of respondents (that earned less than £100,000) is not normally distributed. The upper tail is longer than the lower tail, making this variable positively/upwardly/right skewed.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>E</span>  <span class='chapter-title'>Exercise 7 solutions</span>"
    ]
  },
  {
    "objectID": "exercise7_solutions.html#question-2",
    "href": "exercise7_solutions.html#question-2",
    "title": "Appendix E — Exercise 7 solutions",
    "section": "E.2 Question 2",
    "text": "E.2 Question 2\nBased on the output from question 1, generate a summary table giving the minimum, maximum gross income, and an appropriate measure of the centre and spread of this variable.\n\nSolution\nIn question 1, we saw that the variable was not normally distributed, making the mean and standard deviation inappropriate summary measures. As an alternative, we will display the median as a measure of centre, and the interquartile range (IQR) as a measure of spread.\nTo create a summary table, use the summarise function. Be sure to use the data without the categorised income to avoid invalid results:\n\nsummarise(ehs_tidy_new,\n  min_income = min(gross_income),\n  max_income = max(gross_income),\n  median_income = median(gross_income),\n  iqr_income = IQR(gross_income))\n\n# A tibble: 1 × 4\n  min_income max_income median_income iqr_income\n       &lt;dbl&gt;      &lt;dbl&gt;         &lt;dbl&gt;      &lt;dbl&gt;\n1      3088.     99900.        31768.     33282.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>E</span>  <span class='chapter-title'>Exercise 7 solutions</span>"
    ]
  },
  {
    "objectID": "exercise8_solutions.html",
    "href": "exercise8_solutions.html",
    "title": "Appendix F — Exercise 8 solution",
    "section": "",
    "text": "F.1 Question\nChoose an appropriate visualisation to investigate the change in employment rate between 2008 and 2024. Generate this visualisation and comment on your findings.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>F</span>  <span class='chapter-title'>Exercise 8 solution</span>"
    ]
  },
  {
    "objectID": "exercise8_solutions.html#question",
    "href": "exercise8_solutions.html#question",
    "title": "Appendix F — Exercise 8 solution",
    "section": "",
    "text": "Solution\nA line graph would generally be the most appropriate visualisation to show a numeric variable over time. The visual marking on the graph would be a line, defined by time on the x-axis and employment rate on the y-axis.\nTo create this line graph, we must ensure that all information needed is included in the data. In this case, we will need to create a new time variable, beginning at 1, that combines year and quarter to make up the x-axis:\n\nobr_data &lt;- mutate(obr_data,\n                   time = (year - 2008) * 4 + quarter)\n\nTo build the line graph, we first use the ggplot function and specify the data that we wish to display on the coordinate system. We then use the geom_line function to visualise the data, specifying the variables thatdefine this visualisation:\n\n# Generate the chart area and specify the data\nggplot(data = obr_data) +\n  # Add a line, defined by time on the x-axis, and employment rate on the y\n  geom_line(aes(x = time, y = employment_rate))",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>F</span>  <span class='chapter-title'>Exercise 8 solution</span>"
    ]
  }
]